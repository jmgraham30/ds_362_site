---
title: "Lesson 1"
subtitle: "Overview of Data Mining and Machine Learning"
author: "JMG"
format:
  html:
    code-fold: true
    code-summary: "Show the code"
    toc: true
    toc-location: left
bibliography: lesson01.bib
license: "CC BY-NC-SA 4.0"
---

```{r}
#| echo: false
#| message: false
#| warning: false

# load packages used in document
library(tidyverse)
library(tidytuesdayR)
```


## Learning Objectives

After this lesson, students will be able to:




## Readings, etc.

1) Read Chapter 1 of *An Introduction to Statistical Learning* [@tibshirani2017introduction]. 

2) The following two video lectures are also recommended:

* Motivating problems for machine (statistical) learning. [Watch video on YouTube](https://youtu.be/LvySJGj-88U).
  
```{r}
#| echo: false

vembedr::embed_youtube(id="LvySJGj-88U",height=450) %>%
  vembedr::use_align("center")
```


* Supervised and unsupervised learning. [Watch video on YouTube](https://youtu.be/B9s8rpdNxU0).
  
```{r}
#| echo: false

vembedr::embed_youtube(id="B9s8rpdNxU0",height=450) %>%
  vembedr::use_align("center")
```

3) Skim the README for the [Tidy Tuesday data repository](https://github.com/rfordatascience/tidytuesday) [@TT]. [View the repository.](https://github.com/rfordatascience/tidytuesday) Throughout the semester, we will use example data from the Tidy Tuesday data repository.

## Course Overview

This course provides a coverage of essential topics in data science at the intermediate level with an emphasis on machine learning. Broadly, we will cover algorithms that are commonly used for gaining insight from data. The things you learn in the class will be applicable in a variety of different areas, professions, and even other classes.

There is a website for the course, [view the website](https://knowledge-discovery.netlify.app/). For course logistics, see the official course syllabus, [view the syllabus](https://knowledge-discovery.netlify.app/syllabus.html). Assignments and other information specific to the course in a given semester will be posted on the course learning management system. The course website provides links to many additional resources, [view the links](https://knowledge-discovery.netlify.app/links.html).

While we will refer often to several texts (most of which have been published online as open access materials) throughout the course, most of the content will be delivered via ``notebooks'' like the one you're reading now[^1] that intermix text, mathematical notation, figures, programming language code, and web links. In some cases, you will be asked to go through the notebooks on your own and some times we will go through the notebooks together. Either way, anytime you encounter code in a notebook, it is expected that you will take the time to run any code (mostly by copying and pasting) for yourself. The only way to master the material is through active participation.  

[^1]: The notebooks are created using [Quarto](https://quarto.org/) and [R markdown](https://rmarkdown.rstudio.com/), topics that we will cover in more detail later.  

## Overview of data mining and machine learning



### Review of the Data Science Workflow

Before starting our exploration of machine learning, let's review the basic data science workflow as covered in an introductory level data science course. Generally, the steps in the workflow are:

1) Gather data with the goal of using it to gain insight to answer questions or address problems in a specific domain of application. If you're going to use machine learning as part of your data analysis, this is a good place to make sure that you have enough data and also to split your data into a training set and test set.  

2) Document the data and data collection process. 

    * It is important to think carefully about the type of data that is collected and how the data is generated and collected. Data is often generated or collected in such a way that it will contain or reflect biases, misinformation, incomplete information, or other problematic features. When you use data or models to make a decision, the problematic features of the data may influence the decision made with unforeseen negative consequences. See *The Alignment Problem* by Brian Christian for a thoughtful discussion on the issues related to these types of considerations [@christian2020alignment].  

3) Import the data for analysis. If you have not already, you may want to split your data into a training set and test set.

4) Explore and clean the data. Data visualization is essential at this step. 

5) Generate initial insight or more detailed questions. 

6) Decide what type(s) of analysis or analyses are to be performed. This is the stage at which machine learning enters into the process.  

    * Make sure to clearly state what the goals of an analysis are. There are several different types of analyses of data that are common to conduct. See [Table 1.1](https://datasciencebook.ca/intro.html#tab:questions-table) from [@timbers2022data] for a list of these typical analysis types with corresponding examples of questions appropriate for a particular type of analysis, link to table [here](https://datasciencebook.ca/intro.html#tab:questions-table).

7) Assess the analysis. In particular, use an appropriate metric to estimate model error. 

8) At this stage, it may be necessary to repeat steps 1 - 7.

9) Report your findings/results documenting each step in the analysis, and state your conclusions in the context of the question, problem, or application that motivated your analysis. 


It is essential the our data science workflow be **reproducible** and **auditable**. That is, each step in a data analysis should be accessible and understandable to others (auditability) and anyone with access to your analysis should be able to re-run the analysis from start to finish and get the same result you did (reproducibility).  @fig-reproducible illustrates the concept of reproducibility. 

[![Artwork by Allison Horst](https://github.com/allisonhorst/stats-illustrations/blob/main/rstats-artwork/reproducibility_court.png?raw=1){#fig-reproducible fig-alt="An illustration of the concept of reproducibility."}](https://allisonhorst.com/)

## An `r icons::icon_style(icons::fontawesome("r-project"),scale=2,fill="steelblue")` refresher

For this course, we assume that students have some experience using a programming language like [R](https://www.r-project.org/) or [Python](https://www.python.org/) to analyze data. In particular, it is assumed that students in the course can load, clean and plot data in R or Python. A facility to work with data frames via an R package like [`dplyr`](https://dplyr.tidyverse.org/) or the [`pandas`](https://pandas.pydata.org/) Python library is assumed. We also assume students can use [`ggplot2`](https://ggplot2.tidyverse.org/) in R or [`matplotlib`](https://matplotlib.org/) in Python for making appropriate plots of data.      

[![Artwork by Allison Horst](https://github.com/allisonhorst/stats-illustrations/blob/main/rstats-artwork/exploder.gif?raw=1){fig-alt="A gif showing the logo for the R language for statistical computing."}](https://allisonhorst.com/)


### Why R?

The [R language](https://www.r-project.org/) [@r2023] for statistical computing is one of the most popular computing tools for data science, among the other [most popular](https://www.datacamp.com/blog/top-programming-languages-for-data-scientists-in-2022) are [Python](https://www.python.org/) and [Julia](https://julialang.org/). Some of the strengths of R include

* free and open source which facilitates reproducibility and auditability, 

* ecosystem of packages that greatly extend the functionality of R,

* [rmarkdown](https://rmarkdown.rstudio.com/) [@rmarkdown2020] and [Quarto](https://quarto.org/) frameworks for [literate programming](https://en.wikipedia.org/wiki/Literate_programming) enable presentation and communication of data analyses and facilitate reproducibility and auditability, 

* [RStudio](https://posit.co/download/rstudio-desktop/) [integrated development environment](https://en.wikipedia.org/wiki/Integrated_development_environment) (IDE) by [Posit](https://posit.co/) enhances programming, RStudio also supports other languages like Python and Julia making it possible to work across different languages, 

* a strong and collaborative user community, see R Community Explorer website, [view the website.](https://r-community.org/usergroups/). 

As the course progresses, we will learn a lot of R. For this lesson, we will start with something very simple, that is, doing basic calculations with R. 


## Preparation for the next lesson

For the next lesson:

* Read section 2.1 from of *An Introduction to Statistical Learning* [@tibshirani2017introduction]. You may also want to read sections 2.1 and 2.2 of *Statistical Learning with Math and R* [@suzuki2020statistical].

* Watch the corresponding video lecture on regression. [View on YouTube](https://youtu.be/ox0cKk7h4o0).

```{r}
#| echo: false

vembedr::embed_youtube(id="ox0cKk7h4o0",height=450) %>%
  vembedr::use_align("center")
```


## References

::: {#refs}
:::


:::{.callout-tip collapse="true"}
## Expand for Session Info
```{r}
#| echo: false


library(sessioninfo)
# save the session info as an object
pkg_sesh <- session_info(pkgs = "attached")

# get the quarto version
quarto_version <- system("quarto --version", intern = TRUE)

# inject the quarto info
pkg_sesh$platform$quarto <- paste(
  system("quarto --version", intern = TRUE), 
  "@", 
  quarto::quarto_path()
  )

# print it out
pkg_sesh
```

:::



[![](http://mirrors.creativecommons.org/presskit/buttons/88x31/png/by-nc-sa.png?raw=1){fig-align="left" width=15%}](https://creativecommons.org/licenses/by-nc-sa/4.0/legalcode)
