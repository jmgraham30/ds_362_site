<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.3.450">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="JMG">

<title>DS 362 - Lesson 7</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../site_libs/clipboard/clipboard.min.js"></script>
<script src="../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../site_libs/quarto-search/fuse.min.js"></script>
<script src="../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../">
<script src="../site_libs/quarto-html/quarto.js"></script>
<script src="../site_libs/quarto-html/popper.min.js"></script>
<script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../site_libs/quarto-html/anchor.min.js"></script>
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-text-highlighting-styles">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting-dark.css" rel="prefetch" class="quarto-color-scheme quarto-color-alternate" id="quarto-text-highlighting-styles">
<script src="../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-bootstrap" data-mode="light">
<link href="../site_libs/bootstrap/bootstrap-dark.min.css" rel="prefetch" class="quarto-color-scheme quarto-color-alternate" id="quarto-bootstrap" data-mode="dark">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<link href="../site_libs/vembedr-0.1.5/css/vembedr.css" rel="stylesheet">

  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<link rel="stylesheet" href="../styles.css">
</head>

<body class="floating nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg navbar-dark ">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container">
    <a class="navbar-brand" href="../index.html">
    <span class="navbar-title">DS 362</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link" href="../index.html" rel="" target="">
 <span class="menu-text">Home</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../syllabus.html" rel="" target="">
 <span class="menu-text">Syllabus</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../links.html" rel="" target="">
 <span class="menu-text">Links</span></a>
  </li>  
</ul>
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/jmgraham30/ds_362_site" rel="" target=""><i class="bi bi-github" role="img" aria-label="GitHub">
</i> 
 <span class="menu-text"></span></a>
  </li>  
</ul>
            <div class="quarto-navbar-tools">
  <a href="" class="quarto-color-scheme-toggle quarto-navigation-tool  px-1" onclick="window.quartoToggleColorScheme(); return false;" title="Toggle dark mode"><i class="bi"></i></a>
</div>
          </div> <!-- /navcollapse -->
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal sidebar-navigation floating overflow-auto">
    <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#learning-objectives" id="toc-learning-objectives" class="nav-link active" data-scroll-target="#learning-objectives">Learning Objectives</a></li>
  <li><a href="#readings-etc." id="toc-readings-etc." class="nav-link" data-scroll-target="#readings-etc.">Readings, etc.</a></li>
  <li><a href="#overview" id="toc-overview" class="nav-link" data-scroll-target="#overview">Overview</a>
  <ul class="collapse">
  <li><a href="#describing-a-neural-network" id="toc-describing-a-neural-network" class="nav-link" data-scroll-target="#describing-a-neural-network">Describing a Neural Network</a></li>
  <li><a href="#describing-a-neural-networks-in-r" id="toc-describing-a-neural-networks-in-r" class="nav-link" data-scroll-target="#describing-a-neural-networks-in-r">Describing a Neural Networks in R</a></li>
  <li><a href="#suggestions-for-further-reading" id="toc-suggestions-for-further-reading" class="nav-link" data-scroll-target="#suggestions-for-further-reading">Suggestions for Further Reading</a></li>
  <li><a href="#recent-applications-of-neural-networks-and-deep-learning" id="toc-recent-applications-of-neural-networks-and-deep-learning" class="nav-link" data-scroll-target="#recent-applications-of-neural-networks-and-deep-learning">Recent Applications of Neural Networks and Deep Learning</a></li>
  <li><a href="#sizes-of-neural-networks-in-various-applications" id="toc-sizes-of-neural-networks-in-various-applications" class="nav-link" data-scroll-target="#sizes-of-neural-networks-in-various-applications">Sizes of Neural Networks in Various Applications</a></li>
  </ul></li>
  <li><a href="#neural-networks" id="toc-neural-networks" class="nav-link" data-scroll-target="#neural-networks">Neural Networks</a>
  <ul class="collapse">
  <li><a href="#gradient-descent-for-optimization" id="toc-gradient-descent-for-optimization" class="nav-link" data-scroll-target="#gradient-descent-for-optimization">Gradient Descent for Optimization</a></li>
  <li><a href="#single-layer-networks" id="toc-single-layer-networks" class="nav-link" data-scroll-target="#single-layer-networks">Single Layer Networks</a></li>
  <li><a href="#multilayer-networks" id="toc-multilayer-networks" class="nav-link" data-scroll-target="#multilayer-networks">Multilayer networks</a></li>
  <li><a href="#convolutional-and-recurrent-networks" id="toc-convolutional-and-recurrent-networks" class="nav-link" data-scroll-target="#convolutional-and-recurrent-networks">Convolutional and Recurrent Networks</a></li>
  </ul></li>
  <li><a href="#neural-networks-and-deep-learning-in-r" id="toc-neural-networks-and-deep-learning-in-r" class="nav-link" data-scroll-target="#neural-networks-and-deep-learning-in-r"><svg viewbox="0 0 581 512" style="position:relative;display:inline-block;top:.1em;fill:steelblue;height:2em;" xmlns="http://www.w3.org/2000/svg"> <path d="M581 226.6C581 119.1 450.9 32 290.5 32S0 119.1 0 226.6C0 322.4 103.3 402 239.4 418.1V480h99.1v-61.5c24.3-2.7 47.6-7.4 69.4-13.9L448 480h112l-67.4-113.7c54.5-35.4 88.4-84.9 88.4-139.7zm-466.8 14.5c0-73.5 98.9-133 220.8-133s211.9 40.7 211.9 133c0 50.1-26.5 85-70.3 106.4-2.4-1.6-4.7-2.9-6.4-3.7-10.2-5.2-27.8-10.5-27.8-10.5s86.6-6.4 86.6-92.7-90.6-87.9-90.6-87.9h-199V361c-74.1-21.5-125.2-67.1-125.2-119.9zm225.1 38.3v-55.6c57.8 0 87.8-6.8 87.8 27.3 0 36.5-38.2 28.3-87.8 28.3zm-.9 72.5H365c10.8 0 18.9 11.7 24 19.2-16.1 1.9-33 2.8-50.6 2.9v-22.1z"></path></svg> Neural Networks and Deep Learning in R</a></li>
  <li><a href="#references" id="toc-references" class="nav-link" data-scroll-target="#references">References</a></li>
  </ul>
</nav>
</nav>
<div id="quarto-sidebar-glass" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">Lesson 7</h1>
<p class="subtitle lead">Neural Networks and Deep Learning</p>
</div>



<div class="quarto-title-meta">

    <div>
    <div class="quarto-title-meta-heading">Author</div>
    <div class="quarto-title-meta-contents">
             <p>JMG </p>
          </div>
  </div>
    
  
    
  </div>
  

</header>

<section id="learning-objectives" class="level2">
<h2 class="anchored" data-anchor-id="learning-objectives">Learning Objectives</h2>
<p>After this lesson, students will be able to:</p>
<ul>
<li><p>Describe the structure of a neural network and explain the role of activation functions, loss functions, optimization algorithms, and regularization in neural networks and deep learning.</p></li>
<li><p>Implement the gradient descent algorithm for optimization of simple functions.</p></li>
<li><p>Implement a neural network in R using packages such as <code>brulee</code>, <code>keras</code> or <code>torch</code>.</p></li>
</ul>
</section>
<section id="readings-etc." class="level2">
<h2 class="anchored" data-anchor-id="readings-etc.">Readings, etc.</h2>
<p>For this lesson, refer to the following readings, etc.:</p>
<ul>
<li><p>Read chapter 10 from of <em>An Introduction to Statistical Learning</em> <span class="citation" data-cites="tibshirani2017introduction">(<a href="#ref-tibshirani2017introduction" role="doc-biblioref">Tibshirani, James, and Trevor 2017</a>)</span>.</p></li>
<li><p>Read section 7.1 from <em>Mathematics for Machine Learning</em> <span class="citation" data-cites="deisenroth2020mathematics">(<a href="#ref-deisenroth2020mathematics" role="doc-biblioref">Deisenroth, Faisal, and Ong 2020</a>)</span>. This book is freely available online. <a href="https://mml-book.github.io/">View the book</a>.</p></li>
</ul>
<p>Watch the following video lectures on neural networks:</p>
<ul>
<li><a href="https://youtu.be/jJb2qytbcNg?si=hwdtetIKGC18RbXT">View Introduction to Neural Networks video on YouTube</a>.</li>
</ul>
<div class="cell">
<div class="cell-output-display">
<div class="vembedr" align="center">
<div>
<iframe src="https://www.youtube.com/embed/jJb2qytbcNg?si=hwdtetIKGC18RbXT" width="800" height="450" frameborder="0" allowfullscreen="" data-external="1"></iframe>
</div>
</div>
</div>
</div>
</section>
<section id="overview" class="level2">
<h2 class="anchored" data-anchor-id="overview">Overview</h2>
<p><a href="https://en.wikipedia.org/wiki/Deep_learning">Deep learning</a> is an active area of research in machine learning and artificial intelligence and <a href="https://en.wikipedia.org/wiki/Artificial_neural_network">neural networks</a> are the foundation of deep learning. In this lesson, we will introduce neural networks and discuss how they are used in deep learning.</p>
<p>Neural networks are a class of machine learning models that are inspired by the structure of the brain. They are composed of a series of layers of neurons that are connected to each other. Each artificial neuron is a simple computational unit that takes in a set of inputs, performs a computation, and produces an output. The output of one neuron is then used as the input to the next neuron. The first layer of artificial neurons is called the input layer and the last layer of neurons is called the output layer. The layers in between the input and output layers are called hidden layers. The number of hidden layers in a neural network is called the depth of the network. The number of neurons in each layer is called the width of the network. <a href="#fig-slnn">Figure&nbsp;1</a> shows a neural network with one hidden layer consisting of 4 neurons or nodes. Later we will develop notation to describe neural networks mathematically. From here on out we will ignore the biological analogy that is the historical origin of neural networks and focus on the mathematical model.</p>
<div id="fig-slnn" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="https://www.dropbox.com/scl/fi/t16o0um8wenwr0kq0t6i4/10_1.png?rlkey=epw6xbd5x8qpu9xqtsdmryqaq&amp;raw=1" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">Figure&nbsp;1: A neural network with a single hidden layer consisting of four neurons or nodes.</figcaption>
</figure>
</div>
<p>Neural networks are conceptually simple but the mathematical details can be confusing. The general idea is that a neural network takes an input of <span class="math inline">\(p\)</span> predictor variables <span class="math inline">\(X = (X_{1},X_{2},\ldots , X_{p})\)</span> and builds a <em>nonlinear</em> function <span class="math inline">\(f(X)\)</span> to predict the response <span class="math inline">\(Y\)</span>. What distinguishes neural networks for other nonlinear methods is the particular structure of the model function <span class="math inline">\(f\)</span>.</p>
<section id="describing-a-neural-network" class="level3">
<h3 class="anchored" data-anchor-id="describing-a-neural-network">Describing a Neural Network</h3>
<p>In order to develop some intuition, we will start by exploring an interactive visualization of a neural network via the <a href="https://playground.tensorflow.org/#activation=tanh&amp;batchSize=10&amp;dataset=circle&amp;regDataset=reg-plane&amp;learningRate=0.03&amp;regularizationRate=0&amp;noise=0&amp;networkShape=4,2&amp;seed=0.92779&amp;showTestData=false&amp;discretize=false&amp;percTrainData=50&amp;x=true&amp;y=true&amp;xTimesY=false&amp;xSquared=false&amp;ySquared=false&amp;cosX=false&amp;sinX=false&amp;cosY=false&amp;sinY=false&amp;collectStats=false&amp;problem=classification&amp;initZero=false&amp;hideText=false">Neural Network Playground</a> website. <a href="https://playground.tensorflow.org/#activation=tanh&amp;batchSize=10&amp;dataset=circle&amp;regDataset=reg-plane&amp;learningRate=0.03&amp;regularizationRate=0&amp;noise=0&amp;networkShape=4,2&amp;seed=0.92779&amp;showTestData=false&amp;discretize=false&amp;percTrainData=50&amp;x=true&amp;y=true&amp;xTimesY=false&amp;xSquared=false&amp;ySquared=false&amp;cosX=false&amp;sinX=false&amp;cosY=false&amp;sinY=false&amp;collectStats=false&amp;problem=classification&amp;initZero=false&amp;hideText=false">Visit the Neural Network Playground</a>.</p>
<p>The visualization allows you to create a neural network and then train it on a dataset. The dataset can be a classification problem or a regression problem. The visualization allows you to change the activation function, the number of hidden layers, the number of neurons in each layer, and the learning rate. These are components related to the training of a network that we will define in detail later.</p>
</section>
<section id="describing-a-neural-networks-in-r" class="level3">
<h3 class="anchored" data-anchor-id="describing-a-neural-networks-in-r">Describing a Neural Networks in R</h3>
<p>Let’s also take a look at a simple neural network in R. The <a href="https://brulee.tidymodels.org/index.html"><code>brulee</code></a> package provides a simple interface via a function <code>brulee_mlp()</code> (it’s a good idea to skim the <a href="https://brulee.tidymodels.org/reference/brulee_mlp.html"><code>brulee_mlp</code> documentation</a>) for creating neural networks in R and uses the <code>tidymodels</code> framework for modeling. The code, available via <a href="https://github.com/jmgraham30/nn_class_example/tree/main">this GitHub repo</a>, creates a neural network with one hidden layer and trains it on the <code>penguins</code> dataset. The repository also contains a script with an example of tuning a neural network with a single hidden layer. Let’s examine this together in an RStudio project.</p>
</section>
<section id="suggestions-for-further-reading" class="level3">
<h3 class="anchored" data-anchor-id="suggestions-for-further-reading">Suggestions for Further Reading</h3>
<p>Here are some additional resources on neural networks and deep learning that cover various aspects of the field that we do not have time to go over in this course:</p>
<ol type="1">
<li><p>For historical context, see <em>Thinking Machines: The Quest for Artificial Intelligence–and Where It’s Taking Us Next</em> by Dormehl or <em>Deep Learning</em> by Kelleher.</p></li>
<li><p>For an excellent overview of the types of problems that neural networks and deep learning are well-suited for, see <span class="citation" data-cites="krohn2019deep">(<a href="#ref-krohn2019deep" role="doc-biblioref">Krohn, Beyleveld, and Bassens 2019</a>)</span>.</p></li>
<li><p>For a more detailed introduction to neural networks, see <span class="citation" data-cites="Goodfellow-et-al-2016">(<a href="#ref-Goodfellow-et-al-2016" role="doc-biblioref">Goodfellow, Bengio, and Courville 2016</a>)</span>. This book is accessible online, <a href="https://www.deeplearningbook.org/">view the book</a>.</p></li>
</ol>
</section>
<section id="recent-applications-of-neural-networks-and-deep-learning" class="level3">
<h3 class="anchored" data-anchor-id="recent-applications-of-neural-networks-and-deep-learning">Recent Applications of Neural Networks and Deep Learning</h3>
<ol type="1">
<li><strong>Natural Language Processing (NLP):</strong>
<ul>
<li><em>Example</em>: BERT, GPT-3, and other large transformer models for tasks like language translation, text generation, and sentiment analysis.</li>
<li><em>Learn More</em>: <a href="https://openai.com/research/gpt-3">OpenAI’s GPT-3</a>, <a href="https://ai.google/research/pubs/pub48095">Google’s BERT</a></li>
</ul></li>
<li><strong>Computer Vision:</strong>
<ul>
<li><em>Example</em>: Convolutional Neural Networks (CNNs) for image classification, object detection, and facial recognition.</li>
<li><em>Learn More</em>: <a href="http://www.image-net.org/challenges/LSVRC/">ImageNet Large Scale Visual Recognition Challenge</a></li>
</ul></li>
<li><strong>Healthcare:</strong>
<ul>
<li><em>Example</em>: Using deep learning to analyze medical images, detect diseases, and predict patient outcomes.</li>
<li><em>Learn More</em>: <a href="https://stanfordmlgroup.github.io/projects/chexnet/">Stanford’s CheXNet</a></li>
</ul></li>
<li><strong>Autonomous Vehicles:</strong>
<ul>
<li><em>Example</em>: Self-driving cars rely on neural networks to perceive their surroundings and make decisions.</li>
<li><em>Learn More</em>: <a href="https://waymo.com/technology/">Waymo’s Self-Driving Technology</a></li>
</ul></li>
<li><strong>Recommender Systems:</strong>
<ul>
<li><em>Example</em>: Recommending products, movies, or content to users based on their preferences and behavior.</li>
<li><em>Learn More</em>: <a href="https://help.netflix.com/en/node/100639">Netflix’s Recommendation Algorithm</a></li>
</ul></li>
<li><strong>Finance:</strong>
<ul>
<li><em>Example</em>: Predictive modeling for stock price forecasting, fraud detection, and algorithmic trading.</li>
<li><em>Learn More</em>: <a href="https://github.com/mwitiderrick/stockprice">Stock Price Prediction with LSTM</a></li>
</ul></li>
<li><strong>Voice Assistants:</strong>
<ul>
<li><em>Example</em>: Voice recognition and natural language understanding in smart speakers like Amazon Echo and Google Home.</li>
<li><em>Learn More</em>: <a href="https://developer.amazon.com/en-US/alexa">Amazon Alexa</a></li>
</ul></li>
<li><strong>Generative Adversarial Networks (GANs):</strong>
<ul>
<li><em>Example</em>: Creating art, generating synthetic images, and deepfakes.</li>
<li><em>Learn More</em>: <a href="https://www.nvidia.com/en-us/research/ai-playground/">NVIDIA’s GAN Research</a></li>
</ul></li>
<li><strong>Robotics:</strong>
<ul>
<li><em>Example</em>: Deep reinforcement learning for robot control and autonomous navigation.</li>
<li><em>Learn More</em>: <a href="https://openai.com/research/robotics">OpenAI’s Robotics Research</a></li>
</ul></li>
<li><strong>Climate Science:</strong>
<ul>
<li><em>Example</em>: Using neural networks to analyze climate data, model climate change, and predict extreme weather events.</li>
<li><em>Learn More</em>: <a href="https://deepmind.com/research/case-studies/climate-change">DeepMind’s Climate Science</a></li>
</ul></li>
</ol>
</section>
<section id="sizes-of-neural-networks-in-various-applications" class="level3">
<h3 class="anchored" data-anchor-id="sizes-of-neural-networks-in-various-applications">Sizes of Neural Networks in Various Applications</h3>
<ol type="1">
<li><strong>Natural Language Processing (NLP):</strong>
<ul>
<li><em>GPT-3</em>: GPT-3, developed by OpenAI, is one of the largest language models with 175 billion parameters.</li>
<li><em>BERT</em>: Google’s BERT has 340 million parameters and is highly influential in NLP.</li>
</ul></li>
<li><strong>Computer Vision:</strong>
<ul>
<li><em>ImageNet Models</em>: Models like VGG-16, VGG-19, and ResNet used for image classification have tens of millions of parameters.</li>
<li><em>Large CNNs</em>: In complex computer vision tasks, models can have hundreds of millions of parameters. Examples include Inception models and DenseNet.</li>
</ul></li>
<li><strong>Healthcare:</strong>
<ul>
<li>The size of neural networks in healthcare applications varies, ranging from a few million to tens of millions of parameters for tasks like medical image analysis.</li>
</ul></li>
<li><strong>Autonomous Vehicles:</strong>
<ul>
<li>Neural networks used in autonomous vehicles vary in size. Perception networks processing sensor data may have tens of millions of parameters, while decision-making networks might be smaller.</li>
</ul></li>
<li><strong>Generative Adversarial Networks (GANs):</strong>
<ul>
<li>Large GANs, such as BigGAN, can have hundreds of millions of parameters and are used for image generation.</li>
</ul></li>
<li><strong>Climate Science:</strong>
<ul>
<li>Climate models using deep learning can have varying numbers of parameters, typically in the millions to tens of millions, depending on the model’s complexity.</li>
</ul></li>
</ol>
</section>
</section>
<section id="neural-networks" class="level2">
<h2 class="anchored" data-anchor-id="neural-networks">Neural Networks</h2>
<p>A neural network is a nonlinear function that is described by parameters called weights and bias. Each node or neuron in a layer of the network inputs a linear combination of the outputs from the nodes of the previous layer. The weights and bias parameters specify the linear combination which is passed through an <a href="https://en.wikipedia.org/wiki/Activation_function">activation function</a> to produce the output of the node. The activation function is a nonlinear function, its output defines the output of the node. Later, we will define some typical activation functions.</p>
<p>The output of each node is then used as the input to the nodes of the next layer. The output of the last layer is the output of the neural network. The weights and bias parameters are learned during the training process. The training process involves finding the weights and bias parameters that <strong>minimize a loss function</strong>. The loss function is a measure of how well the neural network is performing on the training data. The goal of training a neural network is to find the weights and bias parameters that minimize the loss function.</p>
<p>As with all of the other machine learning algorithms we have covered so far, deep learning requires us to solve some kind of optimization problem. In the case of neural networks, we seek to find the weights and bias parameters that minimize the loss function. For regression problems, the loss function is typically the mean squared error (MSE). For classification problems, the loss function is typically the cross-entropy loss.</p>
<p>The weights and bias parameters are learned using an algorithm called <a href="https://en.wikipedia.org/wiki/Gradient_descent">gradient descent</a>. Gradient descent is an optimization algorithm that is used to find the minimum of a function. In the context of neural networks, we use gradient descent to find the minimum of the loss function. The loss function is a function of the weights and biases of the neural network. The weights and biases are the parameters of the neural network. The loss function is a measure of how well the neural network is performing on the training data. The goal of training a neural network is to find the weights and bias parameters that minimize the loss function.</p>
<p><a href="https://en.wikipedia.org/wiki/Stochastic_gradient_descent">Stochastic gradient descent</a> (SGD) is a variant of gradient descent that is used to train neural networks. It can be regarded as a stochastic approximation of gradient descent optimization, since it replaces the actual gradient (calculated from the entire data set) by an estimate thereof (calculated from a randomly selected subset of the data). Especially in high-dimensional optimization problems this reduces the very high computational burden, achieving faster iterations in exchange for a lower convergence rate.</p>
<p>Gradient descent and SGD require us to compute the gradient (multi-variable derivative) of the loss function with respect to the weights and bias parameters. The activation function at each node of the network results in a nonlinear function of the parameters we want to optimize. Thus, computing the implementation of gradient descent for neural networks forces us to use the chain rule for derivatives and this becomes a very messy calculation.</p>
<p>A major development in the field of neural networks was the introduction of the <a href="https://en.wikipedia.org/wiki/Backpropagation">backpropagation algorithm</a> by Rumelhart, Hinton, and Williams in 1986. The backpropagation algorithm is an algorithm for training neural networks. This algorithm is used to calculate the gradient of the loss function with respect to the weights and bias parameters. The gradient is then used to update the weights and bias parameters via gradient descent or something similar. The backpropagation algorithm is clever use of the <a href="https://en.wikipedia.org/wiki/Chain_rule">chain rule</a> for derivatives.</p>
<p>We will proceed by getting a feel for gradient descent in the context of functions that are a lot simpler than neural networks.</p>
<section id="gradient-descent-for-optimization" class="level3">
<h3 class="anchored" data-anchor-id="gradient-descent-for-optimization">Gradient Descent for Optimization</h3>
<p>Gradient descent is an iterative optimization algorithm for finding the minimum of a function <span class="math inline">\(f:\mathbb{R}^{d} \rightarrow \mathbb{R}\)</span>. The algorithm starts with an initial guess <span class="math inline">\({\bf x}_{0} \in \mathbb{R}^{d}\)</span> for the minimizing value for the function. The algorithm then iteratively updates the guess by an iteration of the form</p>
<p><span class="math display">\[
{\bf x}_{k+1} = {\bf x}_{k} - \alpha_{k} \nabla f({\bf x}_{k})
\]</span></p>
<p>where <span class="math inline">\(\alpha_{k} &gt; 0\)</span> is the step size and <span class="math inline">\(\nabla f({\bf x}_{k})\)</span> is the gradient of the function <span class="math inline">\(f\)</span> at the point <span class="math inline">\({\bf x}_{k}\)</span>. Recall that the gradient of a function is a vector that points in the direction of the steepest ascent of the function. In practical implementations one often takes the step size <span class="math inline">\(\alpha_{k} = \text{constant}\)</span> for all <span class="math inline">\(k\)</span> and this constant is called the <strong>learning rate</strong>. In the context of neural networks, each step in an iteration of gradient descent is called an <strong>epoch</strong>.</p>
<p>Let’s start with a simple one-dimensional problem. Consider the function</p>
<p><span class="math display">\[
f(x) = x^4 + 7x^3 + 5x^2 - 17x + 3
\]</span> which is plotted in <a href="#fig-quart-fun">Figure&nbsp;2</a>. This function has a global minimum at <span class="math inline">\(x = -4.5\)</span>. We can use gradient descent to find at least approximately the value of <span class="math inline">\(x\)</span> that minimizes <span class="math inline">\(f(x)\)</span>.</p>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a>f <span class="ot">&lt;-</span> <span class="cf">function</span>(x) {</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a>  x<span class="sc">^</span><span class="dv">4</span> <span class="sc">+</span> <span class="dv">7</span><span class="sc">*</span>x<span class="sc">^</span><span class="dv">3</span> <span class="sc">+</span> <span class="dv">5</span><span class="sc">*</span>x<span class="sc">^</span><span class="dv">2</span> <span class="sc">-</span> <span class="dv">17</span><span class="sc">*</span>x <span class="sc">+</span> <span class="dv">3</span></span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a>x <span class="ot">&lt;-</span> <span class="fu">seq</span>(<span class="sc">-</span><span class="dv">6</span>, <span class="dv">2</span>, <span class="at">length.out =</span> <span class="dv">100</span>)</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a><span class="fu">tibble</span>(<span class="at">x =</span> x) <span class="sc">%&gt;%</span> </span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">y =</span> <span class="fu">f</span>(x)) <span class="sc">%&gt;%</span> </span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>(<span class="fu">aes</span>(<span class="at">x =</span> x, <span class="at">y =</span> y)) <span class="sc">+</span></span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_line</span>() <span class="sc">+</span></span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_vline</span>(<span class="at">xintercept =</span> <span class="sc">-</span><span class="fl">4.5</span>, <span class="at">linetype =</span> <span class="st">"dashed"</span>) <span class="sc">+</span></span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="fu">aes</span>(<span class="at">x =</span> <span class="sc">-</span><span class="fl">4.5</span>, <span class="at">y =</span> <span class="fu">f</span>(<span class="sc">-</span><span class="fl">4.5</span>)), <span class="at">color =</span> <span class="st">"purple"</span>, <span class="at">size =</span> <span class="dv">3</span>) <span class="sc">+</span></span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(</span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a>    <span class="at">x =</span> <span class="fu">TeX</span>(<span class="st">"$x$"</span>),</span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a>    <span class="at">y =</span> <span class="fu">TeX</span>(<span class="st">"$f(x)$"</span>),</span>
<span id="cb1-16"><a href="#cb1-16" aria-hidden="true" tabindex="-1"></a>    <span class="at">title =</span> <span class="st">"A polynomial function with a global minimum"</span></span>
<span id="cb1-17"><a href="#cb1-17" aria-hidden="true" tabindex="-1"></a>  )</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display">
<div id="fig-quart-fun" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="index_files/figure-html/fig-quart-fun-1.png" class="img-fluid figure-img" width="672"></p>
<figcaption class="figure-caption">Figure&nbsp;2: A fourth-degree polynomial function with a global minimum at <span class="math inline">\(x = -4.5\)</span>.</figcaption>
</figure>
</div>
</div>
</div>
<p>The gradient (derivative) of <span class="math inline">\(f(x)\)</span> is given by</p>
<p><span class="math display">\[
f'(x) = 4x^3 + 21x^2 + 10x - 17
\]</span></p>
<p>Let’s iterate gradient descent for 25 epochs with a learning rate of <span class="math inline">\(\alpha = 0.01\)</span> and an initial guess of <span class="math inline">\(x_{0} = -3\)</span>. We will plot the value of <span class="math inline">\(x\)</span> at each epoch and the value of the function <span class="math inline">\(f(x)\)</span> at each epoch. We will also plot the value of the gradient at each epoch.</p>
<div class="cell" data-layout-align="center">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a>f_prime <span class="ot">&lt;-</span> <span class="cf">function</span>(x) {</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a>  <span class="dv">4</span><span class="sc">*</span>x<span class="sc">^</span><span class="dv">3</span> <span class="sc">+</span> <span class="dv">21</span><span class="sc">*</span>x<span class="sc">^</span><span class="dv">2</span> <span class="sc">+</span> <span class="dv">10</span><span class="sc">*</span>x <span class="sc">-</span> <span class="dv">17</span></span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a>x <span class="ot">&lt;-</span> <span class="fu">seq</span>(<span class="sc">-</span><span class="dv">6</span>, <span class="dv">2</span>, <span class="at">length.out =</span> <span class="dv">100</span>)</span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a>gd_min <span class="ot">&lt;-</span> <span class="cf">function</span>(x0, </span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a>                  <span class="at">alpha=</span><span class="fl">0.01</span>, </span>
<span id="cb2-9"><a href="#cb2-9" aria-hidden="true" tabindex="-1"></a>                  <span class="at">fun_to_min=</span>f, </span>
<span id="cb2-10"><a href="#cb2-10" aria-hidden="true" tabindex="-1"></a>                  <span class="at">fun_deriv=</span>f_prime, </span>
<span id="cb2-11"><a href="#cb2-11" aria-hidden="true" tabindex="-1"></a>                  <span class="at">n_epochs =</span> <span class="dv">25</span>){</span>
<span id="cb2-12"><a href="#cb2-12" aria-hidden="true" tabindex="-1"></a>  x <span class="ot">&lt;-</span> x0</span>
<span id="cb2-13"><a href="#cb2-13" aria-hidden="true" tabindex="-1"></a>  x_vals <span class="ot">&lt;-</span> <span class="fu">c</span>(x)</span>
<span id="cb2-14"><a href="#cb2-14" aria-hidden="true" tabindex="-1"></a>  y_vals <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="fu">fun_to_min</span>(x))</span>
<span id="cb2-15"><a href="#cb2-15" aria-hidden="true" tabindex="-1"></a>  grad_vals <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="fu">fun_deriv</span>(x))</span>
<span id="cb2-16"><a href="#cb2-16" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb2-17"><a href="#cb2-17" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>n_epochs){</span>
<span id="cb2-18"><a href="#cb2-18" aria-hidden="true" tabindex="-1"></a>    x <span class="ot">&lt;-</span> x <span class="sc">-</span> alpha<span class="sc">*</span><span class="fu">fun_deriv</span>(x)</span>
<span id="cb2-19"><a href="#cb2-19" aria-hidden="true" tabindex="-1"></a>    x_vals <span class="ot">&lt;-</span> <span class="fu">c</span>(x_vals, x)</span>
<span id="cb2-20"><a href="#cb2-20" aria-hidden="true" tabindex="-1"></a>    y_vals <span class="ot">&lt;-</span> <span class="fu">c</span>(y_vals, <span class="fu">fun_to_min</span>(x))</span>
<span id="cb2-21"><a href="#cb2-21" aria-hidden="true" tabindex="-1"></a>    grad_vals <span class="ot">&lt;-</span> <span class="fu">c</span>(grad_vals, <span class="fu">fun_deriv</span>(x))</span>
<span id="cb2-22"><a href="#cb2-22" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb2-23"><a href="#cb2-23" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb2-24"><a href="#cb2-24" aria-hidden="true" tabindex="-1"></a>  <span class="fu">return</span>(<span class="fu">tibble</span>(<span class="at">x =</span> x_vals, <span class="at">y =</span> y_vals, <span class="at">grad =</span> grad_vals))</span>
<span id="cb2-25"><a href="#cb2-25" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb2-26"><a href="#cb2-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-27"><a href="#cb2-27" aria-hidden="true" tabindex="-1"></a>tst <span class="ot">&lt;-</span> <span class="fu">gd_min</span>(<span class="sc">-</span><span class="dv">3</span>)</span>
<span id="cb2-28"><a href="#cb2-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-29"><a href="#cb2-29" aria-hidden="true" tabindex="-1"></a><span class="fu">tibble</span>(<span class="at">x =</span> x) <span class="sc">%&gt;%</span> </span>
<span id="cb2-30"><a href="#cb2-30" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">y =</span> <span class="fu">f</span>(x)) <span class="sc">%&gt;%</span> </span>
<span id="cb2-31"><a href="#cb2-31" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>(<span class="fu">aes</span>(<span class="at">x =</span> x, <span class="at">y =</span> y)) <span class="sc">+</span></span>
<span id="cb2-32"><a href="#cb2-32" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_line</span>() <span class="sc">+</span></span>
<span id="cb2-33"><a href="#cb2-33" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_vline</span>(<span class="at">xintercept =</span> <span class="sc">-</span><span class="fl">4.5</span>, <span class="at">linetype =</span> <span class="st">"dashed"</span>) <span class="sc">+</span></span>
<span id="cb2-34"><a href="#cb2-34" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="fu">aes</span>(<span class="at">x =</span> <span class="sc">-</span><span class="fl">4.5</span>, <span class="at">y =</span> <span class="fu">f</span>(<span class="sc">-</span><span class="fl">4.5</span>)), <span class="at">color =</span> <span class="st">"purple"</span>, <span class="at">size =</span> <span class="dv">3</span>) <span class="sc">+</span></span>
<span id="cb2-35"><a href="#cb2-35" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="at">data =</span> tst, <span class="fu">aes</span>(<span class="at">x =</span> x, <span class="at">y =</span> y, <span class="at">color=</span>y),<span class="at">size=</span><span class="dv">2</span>) <span class="sc">+</span></span>
<span id="cb2-36"><a href="#cb2-36" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(</span>
<span id="cb2-37"><a href="#cb2-37" aria-hidden="true" tabindex="-1"></a>    <span class="at">x =</span> <span class="fu">TeX</span>(<span class="st">"$x$"</span>),</span>
<span id="cb2-38"><a href="#cb2-38" aria-hidden="true" tabindex="-1"></a>    <span class="at">y =</span> <span class="fu">TeX</span>(<span class="st">"$f(x)$"</span>),</span>
<span id="cb2-39"><a href="#cb2-39" aria-hidden="true" tabindex="-1"></a>    <span class="at">title =</span> <span class="fu">TeX</span>(r<span class="st">'(Gradient descent for the function $f(x)$)'</span>)</span>
<span id="cb2-40"><a href="#cb2-40" aria-hidden="true" tabindex="-1"></a>  )</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display">
<div id="fig-quart-grad-descent" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="index_files/figure-html/fig-quart-grad-descent-1.png" class="img-fluid figure-img" width="768"></p>
<figcaption class="figure-caption">Figure&nbsp;3: Gradient descent for the function <span class="math inline">\(f(x)\)</span>.</figcaption>
</figure>
</div>
</div>
</div>
</section>
<section id="single-layer-networks" class="level3">
<h3 class="anchored" data-anchor-id="single-layer-networks">Single Layer Networks</h3>
</section>
<section id="multilayer-networks" class="level3">
<h3 class="anchored" data-anchor-id="multilayer-networks">Multilayer networks</h3>
</section>
<section id="convolutional-and-recurrent-networks" class="level3">
<h3 class="anchored" data-anchor-id="convolutional-and-recurrent-networks">Convolutional and Recurrent Networks</h3>
</section>
</section>
<section id="neural-networks-and-deep-learning-in-r" class="level2">
<h2 class="anchored" data-anchor-id="neural-networks-and-deep-learning-in-r"><svg viewbox="0 0 581 512" style="position:relative;display:inline-block;top:.1em;fill:steelblue;height:2em;" xmlns="http://www.w3.org/2000/svg"> <path d="M581 226.6C581 119.1 450.9 32 290.5 32S0 119.1 0 226.6C0 322.4 103.3 402 239.4 418.1V480h99.1v-61.5c24.3-2.7 47.6-7.4 69.4-13.9L448 480h112l-67.4-113.7c54.5-35.4 88.4-84.9 88.4-139.7zm-466.8 14.5c0-73.5 98.9-133 220.8-133s211.9 40.7 211.9 133c0 50.1-26.5 85-70.3 106.4-2.4-1.6-4.7-2.9-6.4-3.7-10.2-5.2-27.8-10.5-27.8-10.5s86.6-6.4 86.6-92.7-90.6-87.9-90.6-87.9h-199V361c-74.1-21.5-125.2-67.1-125.2-119.9zm225.1 38.3v-55.6c57.8 0 87.8-6.8 87.8 27.3 0 36.5-38.2 28.3-87.8 28.3zm-.9 72.5H365c10.8 0 18.9 11.7 24 19.2-16.1 1.9-33 2.8-50.6 2.9v-22.1z"></path></svg> Neural Networks and Deep Learning in R</h2>
</section>
<section id="references" class="level2">
<h2 class="anchored" data-anchor-id="references">References</h2>
<div id="refs" class="references csl-bib-body hanging-indent" role="list">
<div id="ref-deisenroth2020mathematics" class="csl-entry" role="listitem">
Deisenroth, Marc Peter, A Aldo Faisal, and Cheng Soon Ong. 2020. <em>Mathematics for Machine Learning</em>. Cambridge University Press.
</div>
<div id="ref-Goodfellow-et-al-2016" class="csl-entry" role="listitem">
Goodfellow, Ian, Yoshua Bengio, and Aaron Courville. 2016. <em>Deep Learning</em>. MIT Press.
</div>
<div id="ref-krohn2019deep" class="csl-entry" role="listitem">
Krohn, Jon, Grant Beyleveld, and Aglaé Bassens. 2019. <em>Deep Learning Illustrated</em>. Addison-Wesley Professional.
</div>
<div id="ref-tibshirani2017introduction" class="csl-entry" role="listitem">
Tibshirani, Hastie Robert, Gareth James, and Daniela Witten Trevor. 2017. <em>An Introduction to Statistical Learning</em>. springer publication.
</div>
</div>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-1-contents" aria-controls="callout-1" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Expand for Session Info
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-1" class="callout-1-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<div class="cell">
<div class="cell-output cell-output-stdout">
<pre><code>─ Session info ───────────────────────────────────────────────────────────────
 setting  value
 version  R version 4.3.1 (2023-06-16)
 os       macOS Sonoma 14.0
 system   aarch64, darwin20
 ui       X11
 language (EN)
 collate  en_US.UTF-8
 ctype    en_US.UTF-8
 tz       America/New_York
 date     2023-10-16
 pandoc   3.1.8 @ /opt/homebrew/bin/ (via rmarkdown)
 quarto   1.3.450 @ /usr/local/bin/quarto

─ Packages ───────────────────────────────────────────────────────────────────
 package      * version date (UTC) lib source
 broom        * 1.0.5   2023-06-09 [1] CRAN (R 4.3.0)
 dials        * 1.2.0   2023-04-03 [1] CRAN (R 4.3.0)
 dplyr        * 1.1.3   2023-09-03 [1] CRAN (R 4.3.0)
 forcats      * 1.0.0   2023-01-29 [1] CRAN (R 4.3.0)
 ggplot2      * 3.4.4   2023-10-12 [1] CRAN (R 4.3.1)
 infer        * 1.0.5   2023-09-06 [1] CRAN (R 4.3.0)
 latex2exp    * 0.9.6   2022-11-28 [1] CRAN (R 4.3.0)
 lubridate    * 1.9.3   2023-09-27 [1] CRAN (R 4.3.1)
 modeldata    * 1.2.0   2023-08-09 [1] CRAN (R 4.3.0)
 parsnip      * 1.1.1   2023-08-17 [1] CRAN (R 4.3.0)
 purrr        * 1.0.2   2023-08-10 [1] CRAN (R 4.3.0)
 readr        * 2.1.4   2023-02-10 [1] CRAN (R 4.3.0)
 recipes      * 1.0.8   2023-08-25 [1] CRAN (R 4.3.0)
 rsample      * 1.2.0   2023-08-23 [1] CRAN (R 4.3.0)
 scales       * 1.2.1   2022-08-20 [1] CRAN (R 4.3.0)
 sessioninfo  * 1.2.2   2021-12-06 [1] CRAN (R 4.3.0)
 stringr      * 1.5.0   2022-12-02 [1] CRAN (R 4.3.0)
 tibble       * 3.2.1   2023-03-20 [1] CRAN (R 4.3.0)
 tidymodels   * 1.1.1   2023-08-24 [1] CRAN (R 4.3.0)
 tidyr        * 1.3.0   2023-01-24 [1] CRAN (R 4.3.0)
 tidyverse    * 2.0.0   2023-02-22 [1] CRAN (R 4.3.0)
 tune         * 1.1.2   2023-08-23 [1] CRAN (R 4.3.0)
 workflows    * 1.1.3   2023-02-22 [1] CRAN (R 4.3.0)
 workflowsets * 1.0.1   2023-04-06 [1] CRAN (R 4.3.0)
 yardstick    * 1.2.0   2023-04-21 [1] CRAN (R 4.3.0)

 [1] /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/library

──────────────────────────────────────────────────────────────────────────────</code></pre>
</div>
</div>
</div>
</div>
</div>
<div class="quarto-figure quarto-figure-left">
<figure class="figure">
<p><a href="https://creativecommons.org/licenses/by-nc-sa/4.0/legalcode"><img src="http://mirrors.creativecommons.org/presskit/buttons/88x31/png/by-nc-sa.png?raw=1" class="img-fluid figure-img" style="width:15.0%"></a></p>
</figure>
</div>


</section>

<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents"><h2 class="anchored quarto-appendix-heading">Reuse</h2><div id="quarto-reuse" class="quarto-appendix-contents"><div>CC BY-NC-SA 4.0</div></div></section></div></main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const disableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'prefetch';
    }
  }
  const enableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'stylesheet';
    }
  }
  const manageTransitions = (selector, allowTransitions) => {
    const els = window.document.querySelectorAll(selector);
    for (let i=0; i < els.length; i++) {
      const el = els[i];
      if (allowTransitions) {
        el.classList.remove('notransition');
      } else {
        el.classList.add('notransition');
      }
    }
  }
  const toggleColorMode = (alternate) => {
    // Switch the stylesheets
    const alternateStylesheets = window.document.querySelectorAll('link.quarto-color-scheme.quarto-color-alternate');
    manageTransitions('#quarto-margin-sidebar .nav-link', false);
    if (alternate) {
      enableStylesheet(alternateStylesheets);
      for (const sheetNode of alternateStylesheets) {
        if (sheetNode.id === "quarto-bootstrap") {
          toggleBodyColorMode(sheetNode);
        }
      }
    } else {
      disableStylesheet(alternateStylesheets);
      toggleBodyColorPrimary();
    }
    manageTransitions('#quarto-margin-sidebar .nav-link', true);
    // Switch the toggles
    const toggles = window.document.querySelectorAll('.quarto-color-scheme-toggle');
    for (let i=0; i < toggles.length; i++) {
      const toggle = toggles[i];
      if (toggle) {
        if (alternate) {
          toggle.classList.add("alternate");     
        } else {
          toggle.classList.remove("alternate");
        }
      }
    }
    // Hack to workaround the fact that safari doesn't
    // properly recolor the scrollbar when toggling (#1455)
    if (navigator.userAgent.indexOf('Safari') > 0 && navigator.userAgent.indexOf('Chrome') == -1) {
      manageTransitions("body", false);
      window.scrollTo(0, 1);
      setTimeout(() => {
        window.scrollTo(0, 0);
        manageTransitions("body", true);
      }, 40);  
    }
  }
  const isFileUrl = () => { 
    return window.location.protocol === 'file:';
  }
  const hasAlternateSentinel = () => {  
    let styleSentinel = getColorSchemeSentinel();
    if (styleSentinel !== null) {
      return styleSentinel === "alternate";
    } else {
      return false;
    }
  }
  const setStyleSentinel = (alternate) => {
    const value = alternate ? "alternate" : "default";
    if (!isFileUrl()) {
      window.localStorage.setItem("quarto-color-scheme", value);
    } else {
      localAlternateSentinel = value;
    }
  }
  const getColorSchemeSentinel = () => {
    if (!isFileUrl()) {
      const storageValue = window.localStorage.getItem("quarto-color-scheme");
      return storageValue != null ? storageValue : localAlternateSentinel;
    } else {
      return localAlternateSentinel;
    }
  }
  let localAlternateSentinel = 'default';
  // Dark / light mode switch
  window.quartoToggleColorScheme = () => {
    // Read the current dark / light value 
    let toAlternate = !hasAlternateSentinel();
    toggleColorMode(toAlternate);
    setStyleSentinel(toAlternate);
  };
  // Ensure there is a toggle, if there isn't float one in the top right
  if (window.document.querySelector('.quarto-color-scheme-toggle') === null) {
    const a = window.document.createElement('a');
    a.classList.add('top-right');
    a.classList.add('quarto-color-scheme-toggle');
    a.href = "";
    a.onclick = function() { try { window.quartoToggleColorScheme(); } catch {} return false; };
    const i = window.document.createElement("i");
    i.classList.add('bi');
    a.appendChild(i);
    window.document.body.appendChild(a);
  }
  // Switch to dark mode if need be
  if (hasAlternateSentinel()) {
    toggleColorMode(true);
  } else {
    toggleColorMode(false);
  }
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->



</body></html>