<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.3.450">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="JMG">

<title>DS 362 - Lesson 7</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../site_libs/clipboard/clipboard.min.js"></script>
<script src="../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../site_libs/quarto-search/fuse.min.js"></script>
<script src="../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../">
<script src="../site_libs/quarto-html/quarto.js"></script>
<script src="../site_libs/quarto-html/popper.min.js"></script>
<script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../site_libs/quarto-html/anchor.min.js"></script>
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-text-highlighting-styles">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting-dark.css" rel="prefetch" class="quarto-color-scheme quarto-color-alternate" id="quarto-text-highlighting-styles">
<script src="../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-bootstrap" data-mode="light">
<link href="../site_libs/bootstrap/bootstrap-dark.min.css" rel="prefetch" class="quarto-color-scheme quarto-color-alternate" id="quarto-bootstrap" data-mode="dark">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<link href="../site_libs/vembedr-0.1.5/css/vembedr.css" rel="stylesheet">

  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<link rel="stylesheet" href="../styles.css">
</head>

<body class="floating nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg navbar-dark ">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container">
    <a class="navbar-brand" href="../index.html">
    <span class="navbar-title">DS 362</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link" href="../index.html" rel="" target="">
 <span class="menu-text">Home</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../syllabus.html" rel="" target="">
 <span class="menu-text">Syllabus</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../links.html" rel="" target="">
 <span class="menu-text">Links</span></a>
  </li>  
</ul>
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/jmgraham30/ds_362_site" rel="" target=""><i class="bi bi-github" role="img" aria-label="GitHub">
</i> 
 <span class="menu-text"></span></a>
  </li>  
</ul>
            <div class="quarto-navbar-tools">
  <a href="" class="quarto-color-scheme-toggle quarto-navigation-tool  px-1" onclick="window.quartoToggleColorScheme(); return false;" title="Toggle dark mode"><i class="bi"></i></a>
</div>
          </div> <!-- /navcollapse -->
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal sidebar-navigation floating overflow-auto">
    <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#learning-objectives" id="toc-learning-objectives" class="nav-link active" data-scroll-target="#learning-objectives">Learning Objectives</a></li>
  <li><a href="#readings-etc." id="toc-readings-etc." class="nav-link" data-scroll-target="#readings-etc.">Readings, etc.</a></li>
  <li><a href="#overview" id="toc-overview" class="nav-link" data-scroll-target="#overview">Overview</a>
  <ul class="collapse">
  <li><a href="#exploring-a-neural-network-interactively" id="toc-exploring-a-neural-network-interactively" class="nav-link" data-scroll-target="#exploring-a-neural-network-interactively">Exploring a Neural Network Interactively</a></li>
  <li><a href="#exploring-neural-networks-in-r" id="toc-exploring-neural-networks-in-r" class="nav-link" data-scroll-target="#exploring-neural-networks-in-r">Exploring Neural Networks in R</a></li>
  <li><a href="#suggestions-for-further-reading" id="toc-suggestions-for-further-reading" class="nav-link" data-scroll-target="#suggestions-for-further-reading">Suggestions for Further Reading</a></li>
  </ul></li>
  <li><a href="#neural-networks" id="toc-neural-networks" class="nav-link" data-scroll-target="#neural-networks">Neural Networks</a>
  <ul class="collapse">
  <li><a href="#gradient-descent-for-optimization" id="toc-gradient-descent-for-optimization" class="nav-link" data-scroll-target="#gradient-descent-for-optimization">Gradient Descent for Optimization</a></li>
  <li><a href="#activation-functions" id="toc-activation-functions" class="nav-link" data-scroll-target="#activation-functions">Activation Functions</a></li>
  <li><a href="#single-layer-networks" id="toc-single-layer-networks" class="nav-link" data-scroll-target="#single-layer-networks">Single Layer Networks</a></li>
  </ul></li>
  <li><a href="#multilayer-networks" id="toc-multilayer-networks" class="nav-link" data-scroll-target="#multilayer-networks">Multilayer networks</a>
  <ul class="collapse">
  <li><a href="#backpropagation" id="toc-backpropagation" class="nav-link" data-scroll-target="#backpropagation">Backpropagation</a></li>
  </ul></li>
  <li><a href="#convolutional-and-recurrent-networks" id="toc-convolutional-and-recurrent-networks" class="nav-link" data-scroll-target="#convolutional-and-recurrent-networks">Convolutional and Recurrent Networks</a>
  <ul class="collapse">
  <li><a href="#overview-of-neural-network-types" id="toc-overview-of-neural-network-types" class="nav-link" data-scroll-target="#overview-of-neural-network-types">Overview of Neural Network Types</a></li>
  <li><a href="#convolutional-neural-networks-cnns-1" id="toc-convolutional-neural-networks-cnns-1" class="nav-link" data-scroll-target="#convolutional-neural-networks-cnns-1">Convolutional Neural Networks (CNNs)</a></li>
  <li><a href="#recurrent-neural-networks-rnns-1" id="toc-recurrent-neural-networks-rnns-1" class="nav-link" data-scroll-target="#recurrent-neural-networks-rnns-1">Recurrent Neural Networks (RNNs)</a></li>
  </ul></li>
  <li><a href="#neural-networks-in-r" id="toc-neural-networks-in-r" class="nav-link" data-scroll-target="#neural-networks-in-r"><svg viewbox="0 0 581 512" style="position:relative;display:inline-block;top:.1em;fill:steelblue;height:2em;" xmlns="http://www.w3.org/2000/svg"> <path d="M581 226.6C581 119.1 450.9 32 290.5 32S0 119.1 0 226.6C0 322.4 103.3 402 239.4 418.1V480h99.1v-61.5c24.3-2.7 47.6-7.4 69.4-13.9L448 480h112l-67.4-113.7c54.5-35.4 88.4-84.9 88.4-139.7zm-466.8 14.5c0-73.5 98.9-133 220.8-133s211.9 40.7 211.9 133c0 50.1-26.5 85-70.3 106.4-2.4-1.6-4.7-2.9-6.4-3.7-10.2-5.2-27.8-10.5-27.8-10.5s86.6-6.4 86.6-92.7-90.6-87.9-90.6-87.9h-199V361c-74.1-21.5-125.2-67.1-125.2-119.9zm225.1 38.3v-55.6c57.8 0 87.8-6.8 87.8 27.3 0 36.5-38.2 28.3-87.8 28.3zm-.9 72.5H365c10.8 0 18.9 11.7 24 19.2-16.1 1.9-33 2.8-50.6 2.9v-22.1z"></path></svg> Neural Networks in R</a>
  <ul class="collapse">
  <li><a href="#r-packages-for-neural-networks-and-deep-learning" id="toc-r-packages-for-neural-networks-and-deep-learning" class="nav-link" data-scroll-target="#r-packages-for-neural-networks-and-deep-learning">R Packages for Neural Networks and Deep Learning</a></li>
  </ul></li>
  <li><a href="#further-topics-on-deep-learning" id="toc-further-topics-on-deep-learning" class="nav-link" data-scroll-target="#further-topics-on-deep-learning">Further Topics on Deep Learning</a>
  <ul class="collapse">
  <li><a href="#recent-applications-of-neural-networks-and-deep-learning" id="toc-recent-applications-of-neural-networks-and-deep-learning" class="nav-link" data-scroll-target="#recent-applications-of-neural-networks-and-deep-learning">Recent Applications of Neural Networks and Deep Learning</a></li>
  <li><a href="#sizes-of-neural-networks-in-various-applications" id="toc-sizes-of-neural-networks-in-various-applications" class="nav-link" data-scroll-target="#sizes-of-neural-networks-in-various-applications">Sizes of Neural Networks in Various Applications</a></li>
  <li><a href="#choosing-depth-and-width-of-neural-networks" id="toc-choosing-depth-and-width-of-neural-networks" class="nav-link" data-scroll-target="#choosing-depth-and-width-of-neural-networks">Choosing Depth and Width of Neural Networks</a></li>
  </ul></li>
  <li><a href="#freely-available-libraries-and-packages-for-neural-networks" id="toc-freely-available-libraries-and-packages-for-neural-networks" class="nav-link" data-scroll-target="#freely-available-libraries-and-packages-for-neural-networks">Freely Available Libraries and Packages for Neural Networks</a>
  <ul class="collapse">
  <li><a href="#other-languages" id="toc-other-languages" class="nav-link" data-scroll-target="#other-languages">Other Languages</a></li>
  </ul></li>
  <li><a href="#references" id="toc-references" class="nav-link" data-scroll-target="#references">References</a></li>
  </ul>
</nav>
</nav>
<div id="quarto-sidebar-glass" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">Lesson 7</h1>
<p class="subtitle lead">Neural Networks and Deep Learning</p>
</div>



<div class="quarto-title-meta">

    <div>
    <div class="quarto-title-meta-heading">Author</div>
    <div class="quarto-title-meta-contents">
             <p>JMG </p>
          </div>
  </div>
    
  
    
  </div>
  

</header>

<section id="learning-objectives" class="level2">
<h2 class="anchored" data-anchor-id="learning-objectives">Learning Objectives</h2>
<p>After this lesson, students will be able to:</p>
<ul>
<li><p>Describe the structure of a neural network and explain the role of activation functions, loss functions, optimization algorithms, and regularization in neural networks and deep learning.</p></li>
<li><p>Implement the gradient descent algorithm for optimization of simple functions.</p></li>
<li><p>Implement a neural network in R using packages such as <code>brulee</code>, <code>keras</code> or <code>torch</code>.</p></li>
</ul>
</section>
<section id="readings-etc." class="level2">
<h2 class="anchored" data-anchor-id="readings-etc.">Readings, etc.</h2>
<p>For this lesson, refer to the following readings, etc.:</p>
<ul>
<li><p>Read chapter 10 from of <em>An Introduction to Statistical Learning</em> <span class="citation" data-cites="tibshirani2017introduction">(<a href="#ref-tibshirani2017introduction" role="doc-biblioref">Tibshirani, James, and Trevor 2017</a>)</span>.</p></li>
<li><p>Read section 7.1 from <em>Mathematics for Machine Learning</em> <span class="citation" data-cites="deisenroth2020mathematics">(<a href="#ref-deisenroth2020mathematics" role="doc-biblioref">Deisenroth, Faisal, and Ong 2020</a>)</span>. This book is freely available online. <a href="https://mml-book.github.io/">View the book</a>.</p></li>
</ul>
<p>Watch the following video lectures on neural networks:</p>
<ul>
<li><a href="https://youtu.be/jJb2qytbcNg?si=hwdtetIKGC18RbXT">View Introduction to Neural Networks video on YouTube</a>.</li>
</ul>
<div class="cell">
<div class="cell-output-display">
<div class="vembedr" align="center">
<div>
<iframe src="https://www.youtube.com/embed/jJb2qytbcNg?si=hwdtetIKGC18RbXT" width="800" height="450" frameborder="0" allowfullscreen="" data-external="1"></iframe>
</div>
</div>
</div>
</div>
</section>
<section id="overview" class="level2">
<h2 class="anchored" data-anchor-id="overview">Overview</h2>
<p><a href="https://en.wikipedia.org/wiki/Deep_learning">Deep learning</a> is an active area of research in machine learning and artificial intelligence and <a href="https://en.wikipedia.org/wiki/Artificial_neural_network">neural networks</a> are the foundation of deep learning. In this lesson, we will introduce neural networks and discuss how they are used in deep learning.</p>
<p>Neural networks are a class of machine learning models that are inspired by the structure of the brain. They are composed of a series of layers of neurons that are connected to each other. Each artificial neuron is a simple computational unit that takes in a set of inputs, performs a computation, and produces an output. The output of one neuron is then used as the input to the next neuron. The first layer of artificial neurons is called the input layer and the last layer of neurons is called the output layer. The layers in between the input and output layers are called hidden layers. The number of hidden layers in a neural network is called the depth of the network. The number of neurons in each layer is called the width of the network. <a href="#fig-slnn">Figure&nbsp;1</a> shows a neural network with one hidden layer consisting of 4 neurons or nodes. Later we will develop notation to describe neural networks mathematically. From here on out we will ignore the biological analogy that is the historical origin of neural networks and focus on the mathematical model.</p>
<div id="fig-slnn" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="https://www.dropbox.com/scl/fi/t16o0um8wenwr0kq0t6i4/10_1.png?rlkey=epw6xbd5x8qpu9xqtsdmryqaq&amp;raw=1" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">Figure&nbsp;1: A neural network with a single hidden layer consisting of four neurons or nodes.</figcaption>
</figure>
</div>
<p>Neural networks are conceptually simple but the mathematical details can be confusing. The general idea is that a neural network takes an input of <span class="math inline">\(p\)</span> predictor variables <span class="math inline">\(X = (X_{1},X_{2},\ldots , X_{p})\)</span> and builds a <em>nonlinear</em> function <span class="math inline">\(f(X)\)</span> to predict the response <span class="math inline">\(Y\)</span>. What distinguishes neural networks for other nonlinear methods is the particular structure of the model function <span class="math inline">\(f\)</span>.</p>
<section id="exploring-a-neural-network-interactively" class="level3">
<h3 class="anchored" data-anchor-id="exploring-a-neural-network-interactively">Exploring a Neural Network Interactively</h3>
<p>In order to develop some intuition, we will start by exploring an interactive visualization of a neural network via the <a href="https://playground.tensorflow.org/#activation=tanh&amp;batchSize=10&amp;dataset=circle&amp;regDataset=reg-plane&amp;learningRate=0.03&amp;regularizationRate=0&amp;noise=0&amp;networkShape=4,2&amp;seed=0.92779&amp;showTestData=false&amp;discretize=false&amp;percTrainData=50&amp;x=true&amp;y=true&amp;xTimesY=false&amp;xSquared=false&amp;ySquared=false&amp;cosX=false&amp;sinX=false&amp;cosY=false&amp;sinY=false&amp;collectStats=false&amp;problem=classification&amp;initZero=false&amp;hideText=false">Neural Network Playground</a> website. <a href="https://playground.tensorflow.org/#activation=tanh&amp;batchSize=10&amp;dataset=circle&amp;regDataset=reg-plane&amp;learningRate=0.03&amp;regularizationRate=0&amp;noise=0&amp;networkShape=4,2&amp;seed=0.92779&amp;showTestData=false&amp;discretize=false&amp;percTrainData=50&amp;x=true&amp;y=true&amp;xTimesY=false&amp;xSquared=false&amp;ySquared=false&amp;cosX=false&amp;sinX=false&amp;cosY=false&amp;sinY=false&amp;collectStats=false&amp;problem=classification&amp;initZero=false&amp;hideText=false">Visit the Neural Network Playground</a>.</p>
<p>The visualization allows you to create a neural network and then train it on a dataset. The dataset can be a classification problem or a regression problem. The visualization allows you to change the activation function, the number of hidden layers, the number of neurons in each layer, and the learning rate. These are components related to the training of a network that we will define in detail later.</p>
</section>
<section id="exploring-neural-networks-in-r" class="level3">
<h3 class="anchored" data-anchor-id="exploring-neural-networks-in-r">Exploring Neural Networks in R</h3>
<p>Let’s also take a look at a simple neural network in R. The <a href="https://brulee.tidymodels.org/index.html"><code>brulee</code></a> package provides a simple interface via a function <code>brulee_mlp()</code> (it’s a good idea to skim the <a href="https://brulee.tidymodels.org/reference/brulee_mlp.html"><code>brulee_mlp</code> documentation</a>) for creating neural networks in R and uses the <code>tidymodels</code> framework for modeling. The code, available via <a href="https://github.com/jmgraham30/nn_class_example/tree/main">this GitHub repo</a>, creates a neural network with one hidden layer and trains it on the <code>penguins</code> dataset. The repository also contains a script with an example of tuning a neural network with a single hidden layer. Let’s examine this together in an RStudio project.</p>
</section>
<section id="suggestions-for-further-reading" class="level3">
<h3 class="anchored" data-anchor-id="suggestions-for-further-reading">Suggestions for Further Reading</h3>
<p>Here are some additional resources on neural networks and deep learning that cover various aspects of the field that we do not have time to go over in this course:</p>
<ol type="1">
<li><p>For historical context, see <em>Thinking Machines: The Quest for Artificial Intelligence–and Where It’s Taking Us Next</em> by Dormehl or <em>Deep Learning</em> by Kelleher.</p></li>
<li><p>For an excellent overview of the types of problems that neural networks and deep learning are well-suited for, see <span class="citation" data-cites="krohn2019deep">(<a href="#ref-krohn2019deep" role="doc-biblioref">Krohn, Beyleveld, and Bassens 2019</a>)</span>.</p></li>
<li><p>For a more detailed introduction to neural networks, see <span class="citation" data-cites="Goodfellow-et-al-2016">(<a href="#ref-Goodfellow-et-al-2016" role="doc-biblioref">Goodfellow, Bengio, and Courville 2016</a>)</span>. This book is accessible online, <a href="https://www.deeplearningbook.org/">view the book</a>.</p></li>
</ol>
</section>
</section>
<section id="neural-networks" class="level2">
<h2 class="anchored" data-anchor-id="neural-networks">Neural Networks</h2>
<p>A neural network is a nonlinear function that is described by parameters called weights and bias. Each node or neuron in a layer of the network inputs a linear combination of the outputs from the nodes of the previous layer. The weights and bias parameters specify the linear combination which is passed through an <a href="https://en.wikipedia.org/wiki/Activation_function">activation function</a> to produce the output of the node. The activation function is a nonlinear function, its output defines the output of the node. Later, we will define some typical activation functions.</p>
<p>The output of each node is then used as the input to the nodes of the next layer. The output of the last layer is the output of the neural network. The weights and bias parameters are learned during the training process. The training process involves finding the weights and bias parameters that <strong>minimize a loss function</strong>. The loss function is a measure of how well the neural network is performing on the training data. The goal of training a neural network is to find the weights and bias parameters that minimize the loss function.</p>
<p>As with all of the other machine learning algorithms we have covered so far, deep learning requires us to solve some kind of optimization problem. In the case of neural networks, we seek to find the weights and bias parameters that minimize the loss function. For regression problems, the loss function is typically the mean squared error (MSE). For classification problems, the loss function is typically the cross-entropy loss.</p>
<p>The weights and bias parameters are learned using an algorithm called <a href="https://en.wikipedia.org/wiki/Gradient_descent">gradient descent</a>. Gradient descent is an optimization algorithm that is used to find the minimum of a function. In the context of neural networks, we use gradient descent to find the minimum of the loss function. The loss function is a function of the weights and biases of the neural network. The weights and biases are the parameters of the neural network. The loss function is a measure of how well the neural network is performing on the training data. The goal of training a neural network is to find the weights and bias parameters that minimize the loss function.</p>
<p><a href="https://en.wikipedia.org/wiki/Stochastic_gradient_descent">Stochastic gradient descent</a> (SGD) is a variant of gradient descent that is used to train neural networks. It can be regarded as a stochastic approximation of gradient descent optimization, since it replaces the actual gradient (calculated from the entire data set) by an estimate thereof (calculated from a randomly selected subset of the data). Especially in high-dimensional optimization problems this reduces the very high computational burden, achieving faster iterations in exchange for a lower convergence rate.</p>
<p>Gradient descent and SGD require us to compute the gradient (multi-variable derivative) of the loss function with respect to the weights and bias parameters. The activation function at each node of the network results in a nonlinear function of the parameters we want to optimize. Thus, computing the implementation of gradient descent for neural networks forces us to use the chain rule for derivatives and this becomes a very messy calculation.</p>
<p>A major development in the field of neural networks was the introduction of the <a href="https://en.wikipedia.org/wiki/Backpropagation">backpropagation algorithm</a> by Rumelhart, Hinton, and Williams in 1986. The backpropagation algorithm is an algorithm for training neural networks. This algorithm is used to calculate the gradient of the loss function with respect to the weights and bias parameters. The gradient is then used to update the weights and bias parameters via gradient descent or something similar. The backpropagation algorithm is clever use of the <a href="https://en.wikipedia.org/wiki/Chain_rule">chain rule</a> for derivatives.</p>
<p>We will proceed by getting a feel for gradient descent in the context of functions that are a lot simpler than neural networks.</p>
<section id="gradient-descent-for-optimization" class="level3">
<h3 class="anchored" data-anchor-id="gradient-descent-for-optimization">Gradient Descent for Optimization</h3>
<p>Gradient descent is an iterative optimization algorithm for finding the minimum of a function <span class="math inline">\(f:\mathbb{R}^{d} \rightarrow \mathbb{R}\)</span>. The algorithm starts with an initial guess <span class="math inline">\({\bf x}_{0} \in \mathbb{R}^{d}\)</span> for the minimizing value for the function. The algorithm then iteratively updates the guess by an iteration of the form</p>
<p><span class="math display">\[
{\bf x}_{k+1} = {\bf x}_{k} - \alpha_{k} \nabla f({\bf x}_{k})
\]</span></p>
<p>where <span class="math inline">\(\alpha_{k} &gt; 0\)</span> is the step size and <span class="math inline">\(\nabla f({\bf x}_{k})\)</span> is the gradient of the function <span class="math inline">\(f\)</span> at the point <span class="math inline">\({\bf x}_{k}\)</span>. Recall that the gradient of a function is a vector that points in the direction of the steepest ascent of the function. In practical implementations one often takes the step size <span class="math inline">\(\alpha_{k} = \text{constant}\)</span> for all <span class="math inline">\(k\)</span> and this constant is called the <strong>learning rate</strong>. In the context of neural networks, each step in an iteration of gradient descent is called an <strong>epoch</strong>.</p>
<p>Let’s start with a simple one-dimensional problem. Consider the function</p>
<p><span class="math display">\[
f(x) = x^4 + 7x^3 + 5x^2 - 17x + 3
\]</span> which is plotted in <a href="#fig-quart-fun">Figure&nbsp;2</a>. This function has a global minimum at <span class="math inline">\(x = -4.5\)</span>. We can use gradient descent to find at least approximately the value of <span class="math inline">\(x\)</span> that minimizes <span class="math inline">\(f(x)\)</span>.</p>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a>f <span class="ot">&lt;-</span> <span class="cf">function</span>(x) {</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a>  x<span class="sc">^</span><span class="dv">4</span> <span class="sc">+</span> <span class="dv">7</span><span class="sc">*</span>x<span class="sc">^</span><span class="dv">3</span> <span class="sc">+</span> <span class="dv">5</span><span class="sc">*</span>x<span class="sc">^</span><span class="dv">2</span> <span class="sc">-</span> <span class="dv">17</span><span class="sc">*</span>x <span class="sc">+</span> <span class="dv">3</span></span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a>x <span class="ot">&lt;-</span> <span class="fu">seq</span>(<span class="sc">-</span><span class="dv">6</span>, <span class="dv">2</span>, <span class="at">length.out =</span> <span class="dv">100</span>)</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a><span class="fu">tibble</span>(<span class="at">x =</span> x) <span class="sc">%&gt;%</span> </span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">y =</span> <span class="fu">f</span>(x)) <span class="sc">%&gt;%</span> </span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>(<span class="fu">aes</span>(<span class="at">x =</span> x, <span class="at">y =</span> y)) <span class="sc">+</span></span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_line</span>() <span class="sc">+</span></span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_vline</span>(<span class="at">xintercept =</span> <span class="sc">-</span><span class="fl">4.5</span>, <span class="at">linetype =</span> <span class="st">"dashed"</span>) <span class="sc">+</span></span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="fu">aes</span>(<span class="at">x =</span> <span class="sc">-</span><span class="fl">4.5</span>, <span class="at">y =</span> <span class="fu">f</span>(<span class="sc">-</span><span class="fl">4.5</span>)), <span class="at">color =</span> <span class="st">"purple"</span>, <span class="at">size =</span> <span class="dv">3</span>) <span class="sc">+</span></span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(</span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a>    <span class="at">x =</span> <span class="fu">TeX</span>(<span class="st">"$x$"</span>),</span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a>    <span class="at">y =</span> <span class="fu">TeX</span>(<span class="st">"$f(x)$"</span>),</span>
<span id="cb1-16"><a href="#cb1-16" aria-hidden="true" tabindex="-1"></a>    <span class="at">title =</span> <span class="st">"A polynomial function with a global minimum"</span></span>
<span id="cb1-17"><a href="#cb1-17" aria-hidden="true" tabindex="-1"></a>  )</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display">
<div id="fig-quart-fun" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="index_files/figure-html/fig-quart-fun-1.png" class="img-fluid figure-img" width="672"></p>
<figcaption class="figure-caption">Figure&nbsp;2: A fourth-degree polynomial function with a global minimum at <span class="math inline">\(x = -4.5\)</span>.</figcaption>
</figure>
</div>
</div>
</div>
<p>The gradient (derivative) of <span class="math inline">\(f(x)\)</span> is given by</p>
<p><span class="math display">\[
f'(x) = 4x^3 + 21x^2 + 10x - 17
\]</span></p>
<p>Let’s iterate gradient descent for 25 epochs with a learning rate of <span class="math inline">\(\alpha = 0.01\)</span> and an initial guess of <span class="math inline">\(x_{0} = -3\)</span>. We will plot the value of <span class="math inline">\(x\)</span> at each epoch and the value of the function <span class="math inline">\(f(x)\)</span> at each epoch. We will also plot the value of the gradient at each epoch.</p>
<div class="cell" data-layout-align="center">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a>f_prime <span class="ot">&lt;-</span> <span class="cf">function</span>(x) {</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a>  <span class="dv">4</span><span class="sc">*</span>x<span class="sc">^</span><span class="dv">3</span> <span class="sc">+</span> <span class="dv">21</span><span class="sc">*</span>x<span class="sc">^</span><span class="dv">2</span> <span class="sc">+</span> <span class="dv">10</span><span class="sc">*</span>x <span class="sc">-</span> <span class="dv">17</span></span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a>x <span class="ot">&lt;-</span> <span class="fu">seq</span>(<span class="sc">-</span><span class="dv">6</span>, <span class="dv">2</span>, <span class="at">length.out =</span> <span class="dv">100</span>)</span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a>gd_min <span class="ot">&lt;-</span> <span class="cf">function</span>(x0, </span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a>                  <span class="at">alpha=</span><span class="fl">0.01</span>, </span>
<span id="cb2-9"><a href="#cb2-9" aria-hidden="true" tabindex="-1"></a>                  <span class="at">fun_to_min=</span>f, </span>
<span id="cb2-10"><a href="#cb2-10" aria-hidden="true" tabindex="-1"></a>                  <span class="at">fun_deriv=</span>f_prime, </span>
<span id="cb2-11"><a href="#cb2-11" aria-hidden="true" tabindex="-1"></a>                  <span class="at">n_epochs =</span> <span class="dv">25</span>){</span>
<span id="cb2-12"><a href="#cb2-12" aria-hidden="true" tabindex="-1"></a>  x <span class="ot">&lt;-</span> x0</span>
<span id="cb2-13"><a href="#cb2-13" aria-hidden="true" tabindex="-1"></a>  x_vals <span class="ot">&lt;-</span> <span class="fu">c</span>(x)</span>
<span id="cb2-14"><a href="#cb2-14" aria-hidden="true" tabindex="-1"></a>  y_vals <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="fu">fun_to_min</span>(x))</span>
<span id="cb2-15"><a href="#cb2-15" aria-hidden="true" tabindex="-1"></a>  grad_vals <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="fu">fun_deriv</span>(x))</span>
<span id="cb2-16"><a href="#cb2-16" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb2-17"><a href="#cb2-17" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>n_epochs){</span>
<span id="cb2-18"><a href="#cb2-18" aria-hidden="true" tabindex="-1"></a>    x <span class="ot">&lt;-</span> x <span class="sc">-</span> alpha<span class="sc">*</span><span class="fu">fun_deriv</span>(x)</span>
<span id="cb2-19"><a href="#cb2-19" aria-hidden="true" tabindex="-1"></a>    x_vals <span class="ot">&lt;-</span> <span class="fu">c</span>(x_vals, x)</span>
<span id="cb2-20"><a href="#cb2-20" aria-hidden="true" tabindex="-1"></a>    y_vals <span class="ot">&lt;-</span> <span class="fu">c</span>(y_vals, <span class="fu">fun_to_min</span>(x))</span>
<span id="cb2-21"><a href="#cb2-21" aria-hidden="true" tabindex="-1"></a>    grad_vals <span class="ot">&lt;-</span> <span class="fu">c</span>(grad_vals, <span class="fu">fun_deriv</span>(x))</span>
<span id="cb2-22"><a href="#cb2-22" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb2-23"><a href="#cb2-23" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb2-24"><a href="#cb2-24" aria-hidden="true" tabindex="-1"></a>  <span class="fu">return</span>(<span class="fu">tibble</span>(<span class="at">x =</span> x_vals, <span class="at">y =</span> y_vals, <span class="at">grad =</span> grad_vals))</span>
<span id="cb2-25"><a href="#cb2-25" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb2-26"><a href="#cb2-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-27"><a href="#cb2-27" aria-hidden="true" tabindex="-1"></a>tst <span class="ot">&lt;-</span> <span class="fu">gd_min</span>(<span class="sc">-</span><span class="dv">3</span>)</span>
<span id="cb2-28"><a href="#cb2-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-29"><a href="#cb2-29" aria-hidden="true" tabindex="-1"></a><span class="fu">tibble</span>(<span class="at">x =</span> x) <span class="sc">%&gt;%</span> </span>
<span id="cb2-30"><a href="#cb2-30" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">y =</span> <span class="fu">f</span>(x)) <span class="sc">%&gt;%</span> </span>
<span id="cb2-31"><a href="#cb2-31" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>(<span class="fu">aes</span>(<span class="at">x =</span> x, <span class="at">y =</span> y)) <span class="sc">+</span></span>
<span id="cb2-32"><a href="#cb2-32" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_line</span>() <span class="sc">+</span></span>
<span id="cb2-33"><a href="#cb2-33" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_vline</span>(<span class="at">xintercept =</span> <span class="sc">-</span><span class="fl">4.5</span>, <span class="at">linetype =</span> <span class="st">"dashed"</span>) <span class="sc">+</span></span>
<span id="cb2-34"><a href="#cb2-34" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="fu">aes</span>(<span class="at">x =</span> <span class="sc">-</span><span class="fl">4.5</span>, <span class="at">y =</span> <span class="fu">f</span>(<span class="sc">-</span><span class="fl">4.5</span>)), <span class="at">color =</span> <span class="st">"purple"</span>, <span class="at">size =</span> <span class="dv">3</span>) <span class="sc">+</span></span>
<span id="cb2-35"><a href="#cb2-35" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="at">data =</span> tst, <span class="fu">aes</span>(<span class="at">x =</span> x, <span class="at">y =</span> y, <span class="at">color=</span>y),<span class="at">size=</span><span class="dv">2</span>) <span class="sc">+</span></span>
<span id="cb2-36"><a href="#cb2-36" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(</span>
<span id="cb2-37"><a href="#cb2-37" aria-hidden="true" tabindex="-1"></a>    <span class="at">x =</span> <span class="fu">TeX</span>(<span class="st">"$x$"</span>),</span>
<span id="cb2-38"><a href="#cb2-38" aria-hidden="true" tabindex="-1"></a>    <span class="at">y =</span> <span class="fu">TeX</span>(<span class="st">"$f(x)$"</span>),</span>
<span id="cb2-39"><a href="#cb2-39" aria-hidden="true" tabindex="-1"></a>    <span class="at">title =</span> <span class="fu">TeX</span>(r<span class="st">'(Gradient descent for the function $f(x)$)'</span>)</span>
<span id="cb2-40"><a href="#cb2-40" aria-hidden="true" tabindex="-1"></a>  )</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display">
<div id="fig-quart-grad-descent" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="index_files/figure-html/fig-quart-grad-descent-1.png" class="img-fluid figure-img" width="768"></p>
<figcaption class="figure-caption">Figure&nbsp;3: Gradient descent for the function <span class="math inline">\(f(x)\)</span>.</figcaption>
</figure>
</div>
</div>
</div>
</section>
<section id="activation-functions" class="level3">
<h3 class="anchored" data-anchor-id="activation-functions">Activation Functions</h3>
<ol type="1">
<li><p><strong>Sigmoid Activation Function:</strong></p>
<ul>
<li><em>Description</em>: The sigmoid activation function is commonly used in neural networks for binary classification tasks. It maps input values to the range ((0, 1)), making it suitable for output layers of binary classifiers.</li>
<li><em>Mathematical Expression</em>:</li>
</ul>
<p><span class="math display">\[
\text{Sigmoid}(x) = \frac{1}{1 + e^{-x}}
\]</span></p></li>
<li><p><strong>ReLU (Rectified Linear Unit) Activation Function:</strong></p>
<ul>
<li><em>Description</em>: ReLU is a widely used activation function that introduces non-linearity by returning the input for positive values and zero for negative values. It helps mitigate the vanishing gradient problem.</li>
<li><em>Mathematical Expression</em>:</li>
</ul>
<p><span class="math display">\[
\text{ReLU}(x) = \max(0, x)
\]</span></p></li>
<li><p><strong>Tanh (Hyperbolic Tangent) Activation Function:</strong></p>
<ul>
<li><em>Description</em>: Tanh is another common activation function that maps input values to the range ((-1, 1)). It provides zero-centered output, which can help training converge faster.</li>
<li><em>Mathematical Expression</em>:</li>
</ul>
<p><span class="math display">\[
\text{Tanh}(x) = \frac{e^x - e^{-x}}{e^x + e^{-x}}
\]</span></p></li>
<li><p><strong>Leaky ReLU Activation Function:</strong></p>
<ul>
<li><em>Description</em>: Leaky ReLU is a variation of ReLU that allows a small gradient when the input is negative. It addresses the “dying ReLU” problem by preventing neurons from becoming inactive.</li>
<li><em>Mathematical Expression</em>:</li>
</ul>
<p><span class="math display">\[
\text{Leaky ReLU}(x) = \begin{cases} x, &amp; \text{if } x \geq 0 \\ \alpha x, &amp; \text{if } x &lt; 0 \end{cases}
\]</span></p></li>
</ol>
<p>where <span class="math inline">\(\alpha\)</span> is a small constant.</p>
<p><a href="#fig-activation-functions">Figure&nbsp;4</a> shows the plot for each of the activation functions we defined.</p>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a data frame with x values</span></span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a>x <span class="ot">&lt;-</span> <span class="fu">seq</span>(<span class="sc">-</span><span class="dv">3</span>, <span class="dv">3</span>, <span class="at">length.out =</span> <span class="dv">1000</span>)</span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a>df <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(<span class="at">x =</span> x)</span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Sigmoid Activation Function</span></span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a>df<span class="sc">$</span>sigmoid <span class="ot">&lt;-</span> <span class="dv">1</span> <span class="sc">/</span> (<span class="dv">1</span> <span class="sc">+</span> <span class="fu">exp</span>(<span class="sc">-</span>x))</span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-8"><a href="#cb3-8" aria-hidden="true" tabindex="-1"></a><span class="co"># ReLU (Rectified Linear Unit) Activation Function</span></span>
<span id="cb3-9"><a href="#cb3-9" aria-hidden="true" tabindex="-1"></a>df<span class="sc">$</span>relu <span class="ot">&lt;-</span> <span class="fu">pmax</span>(<span class="dv">0</span>, x)</span>
<span id="cb3-10"><a href="#cb3-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-11"><a href="#cb3-11" aria-hidden="true" tabindex="-1"></a><span class="co"># Tanh (Hyperbolic Tangent) Activation Function</span></span>
<span id="cb3-12"><a href="#cb3-12" aria-hidden="true" tabindex="-1"></a>df<span class="sc">$</span>tanh <span class="ot">&lt;-</span> (<span class="fu">exp</span>(x) <span class="sc">-</span> <span class="fu">exp</span>(<span class="sc">-</span>x)) <span class="sc">/</span> (<span class="fu">exp</span>(x) <span class="sc">+</span> <span class="fu">exp</span>(<span class="sc">-</span>x))</span>
<span id="cb3-13"><a href="#cb3-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-14"><a href="#cb3-14" aria-hidden="true" tabindex="-1"></a><span class="co"># Leaky ReLU Activation Function</span></span>
<span id="cb3-15"><a href="#cb3-15" aria-hidden="true" tabindex="-1"></a>leaky_relu <span class="ot">&lt;-</span> <span class="cf">function</span>(x, <span class="at">alpha =</span> <span class="fl">0.03</span>) {</span>
<span id="cb3-16"><a href="#cb3-16" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ifelse</span>(x <span class="sc">&gt;=</span> <span class="dv">0</span>, x, alpha <span class="sc">*</span> x)</span>
<span id="cb3-17"><a href="#cb3-17" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb3-18"><a href="#cb3-18" aria-hidden="true" tabindex="-1"></a>df<span class="sc">$</span>leaky_relu <span class="ot">&lt;-</span> <span class="fu">leaky_relu</span>(x)</span>
<span id="cb3-19"><a href="#cb3-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-20"><a href="#cb3-20" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot the activation functions</span></span>
<span id="cb3-21"><a href="#cb3-21" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(df, <span class="fu">aes</span>(x)) <span class="sc">+</span></span>
<span id="cb3-22"><a href="#cb3-22" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_line</span>(<span class="fu">aes</span>(<span class="at">y =</span> sigmoid, <span class="at">color =</span> <span class="st">"Sigmoid"</span>), <span class="at">linewidth =</span> <span class="dv">1</span>) <span class="sc">+</span></span>
<span id="cb3-23"><a href="#cb3-23" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_line</span>(<span class="fu">aes</span>(<span class="at">y =</span> relu, <span class="at">color =</span> <span class="st">"ReLU"</span>), <span class="at">linewidth =</span> <span class="dv">1</span>) <span class="sc">+</span></span>
<span id="cb3-24"><a href="#cb3-24" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_line</span>(<span class="fu">aes</span>(<span class="at">y =</span> tanh, <span class="at">color =</span> <span class="st">"Tanh"</span>), <span class="at">linewidth =</span> <span class="dv">1</span>) <span class="sc">+</span></span>
<span id="cb3-25"><a href="#cb3-25" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_line</span>(<span class="fu">aes</span>(<span class="at">y =</span> leaky_relu, <span class="at">color =</span> <span class="st">"Leaky ReLU"</span>), <span class="at">linewidth =</span> <span class="dv">1</span>) <span class="sc">+</span></span>
<span id="cb3-26"><a href="#cb3-26" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(</span>
<span id="cb3-27"><a href="#cb3-27" aria-hidden="true" tabindex="-1"></a>    <span class="at">title =</span> <span class="st">"Common Activation Functions for Neural Networks"</span>,</span>
<span id="cb3-28"><a href="#cb3-28" aria-hidden="true" tabindex="-1"></a>    <span class="at">x =</span> <span class="st">"Input (x)"</span>,</span>
<span id="cb3-29"><a href="#cb3-29" aria-hidden="true" tabindex="-1"></a>    <span class="at">y =</span> <span class="st">"Output"</span>,</span>
<span id="cb3-30"><a href="#cb3-30" aria-hidden="true" tabindex="-1"></a>    <span class="at">color =</span> <span class="st">"Activation Function"</span></span>
<span id="cb3-31"><a href="#cb3-31" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">+</span></span>
<span id="cb3-32"><a href="#cb3-32" aria-hidden="true" tabindex="-1"></a>  <span class="fu">scale_color_manual</span>(<span class="at">values =</span> <span class="fu">c</span>(<span class="st">"Sigmoid"</span> <span class="ot">=</span> <span class="st">"#E69F00"</span>, <span class="st">"ReLU"</span> <span class="ot">=</span> <span class="st">"#56B4E9"</span>, <span class="st">"Tanh"</span> <span class="ot">=</span> <span class="st">"#009E73"</span>, <span class="st">"Leaky ReLU"</span> <span class="ot">=</span> <span class="st">"#CC79A7"</span>)) <span class="sc">+</span></span>
<span id="cb3-33"><a href="#cb3-33" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_minimal</span>()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display">
<div id="fig-activation-functions" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="index_files/figure-html/fig-activation-functions-1.png" class="img-fluid figure-img" width="672"></p>
<figcaption class="figure-caption">Figure&nbsp;4: Activation functions used in neural networks.</figcaption>
</figure>
</div>
</div>
</div>
</section>
<section id="single-layer-networks" class="level3">
<h3 class="anchored" data-anchor-id="single-layer-networks">Single Layer Networks</h3>
<p>A single layer neural network is the simplest type of neural network. It consists of a single layer of neurons that take in a set of inputs and produce a set of outputs. The output is computed by applying an activation function to a weighted sum of the inputs. We can describe a single layer neural network with <span class="math inline">\(K\)</span> hidden units mathematically via</p>
<p><span class="math display">\[
\begin{align*}
f(X) &amp;= \beta_{0} + \sum_{k=1}^{K}\beta_{k}h_{k}(X) \\
     &amp;= \beta_{0} + \sum_{k=1}^{K}\beta_{k}g\left(w_{k0} + \sum_{j=1}^{p}w_{kj}X_{j}\right)
\end{align*}
\]</span> where <span class="math inline">\(g\)</span> is some activation function. Notice that a single layer neural network with <span class="math inline">\(p\)</span> inputs and <span class="math inline">\(K\)</span> hidden units has <span class="math inline">\(1 + K + K + pK = 1 + (p+2)K\)</span> parameters. We can view a single layer neural network as a generalized linear model with <span class="math inline">\(K\)</span> basis functions. That is, a linear regression in <span class="math inline">\(K\)</span> activation functions.</p>
<p>To gain some perspective on what the nonlinearity in an single layer neural network allows us to capture, let’s look at a simple example. Suppose that we have <span class="math inline">\(p=2\)</span> input variables <span class="math inline">\(X_{1}\)</span> and <span class="math inline">\(X_{2}\)</span> and <span class="math inline">\(K=2\)</span> hidden units. Further, suppose that our activation function is <span class="math inline">\(g(z) = z^2\)</span>. Set the following parameters:</p>
<p><span class="math display">\[
\begin{array}{ccc} \beta_{0} = 0, &amp; \beta_{1} = \frac{1}{4}, &amp; \beta_{2} = -\frac{1}{4} \\ w_{10} = 0, &amp; w_{11} = 1, &amp; w_{12} = 1, \\ w_{20} = 0, &amp; w_{21} = 1, &amp; w_{22} = -1.   \end{array}
\]</span></p>
<p>Then,</p>
<p><span class="math display">\[
\begin{align*}
h_{1} &amp;= (0 + X_{1} + X_{2})^2, \\
h_{2} &amp;= (0 + X_{1} - X_{2})^2.
\end{align*}
\]</span></p>
<p>Thus,</p>
<p><span class="math display">\[
\begin{align*}
f(X) &amp;= \beta_{0} + \beta_{1}h_{1} + \beta_{2}h_{2} \\
     &amp;= 0 + \frac{1}{4}(X_{1} + X_{2})^2 - \frac{1}{4}(X_{1} - X_{2})^2 \\
     &amp;= \frac{1}{4}(X_{1}^2 + 2X_{1}X_{2} + X_{2}^2) - \frac{1}{4}(X_{1}^2 - 2X_{1}X_{2} + X_{2}^2) \\
     &amp;= X_{1}X_{2}.
\end{align*}
\]</span></p>
<p>So, we see that the sum of two nonlinear transformations of linear functions can produce an interaction term. This is a somewhat artificial example but the point is that the nonlinearity in a single layer neural network via an activation function can “detect” a variety of features in our data.</p>
</section>
</section>
<section id="multilayer-networks" class="level2">
<h2 class="anchored" data-anchor-id="multilayer-networks">Multilayer networks</h2>
<p>In principle, a single layer neural network can approximate most functions of interest in machine learning. This is a consequence of a family of results known as <a href="https://en.wikipedia.org/wiki/Universal_approximation_theorem">universal approximation theorems</a>. However, in practice, deep learning is improved by using multiple layers. A neural network with multiple layers is known as a multilayer neural network. Let’s examine the training of a multilayer neural network in more detail.</p>
<section id="backpropagation" class="level3">
<h3 class="anchored" data-anchor-id="backpropagation">Backpropagation</h3>
<p>The implementation of gradient descent or its variant in deep learning typically require use to compute the gradient of chains of functions like</p>
<p><span class="math display">\[
{\bf y} = (f_{K} \circ f_{K-1} \circ \cdots \circ f_{1})({\bf x})
\]</span> where <span class="math inline">\({\bf x}\)</span> are the inputs, <span class="math inline">\({\bf y}\)</span> are the observations, and every <span class="math inline">\(f_{i}\)</span> has its own parameters. In neural networks,</p>
<p><span class="math display">\[
f_{i}({\bf x}_{i-1}) = \sigma({\bf W}_{i-1}{\bf x}_{i-1} + {\bf b}_{i-1})
\]</span> is the activation function for the <span class="math inline">\(i\)</span>-th layer, where <span class="math inline">\({\bf W}_{i-1}\)</span> is the weight matrix and <span class="math inline">\({\bf b}_{i-1}\)</span> is the bias vector. Here, <span class="math inline">\({\bf x}_{i-1}\)</span> is the output from layer <span class="math inline">\(i-1\)</span>. To train such a model, we need to compute the gradient of the loss function with respect to the parameters <span class="math inline">\({\bf W}_{i}\)</span> and <span class="math inline">\({\bf b}_{i}\)</span> for each layer <span class="math inline">\(i\)</span>. This is done via the <a href="https://en.wikipedia.org/wiki/Backpropagation">backpropagation</a> algorithm. We will now explain how this works. For a reference, see section 5.6.1 from <span class="citation" data-cites="deisenroth2020mathematics">(<a href="#ref-deisenroth2020mathematics" role="doc-biblioref">Deisenroth, Faisal, and Ong 2020</a>)</span>. See also <a href="https://people.cs.umass.edu/~domke/courses/sml2011/08autodiff_nnets.pdf">these online notes</a>.</p>
</section>
</section>
<section id="convolutional-and-recurrent-networks" class="level2">
<h2 class="anchored" data-anchor-id="convolutional-and-recurrent-networks">Convolutional and Recurrent Networks</h2>
<section id="overview-of-neural-network-types" class="level3">
<h3 class="anchored" data-anchor-id="overview-of-neural-network-types">Overview of Neural Network Types</h3>
<p>Thus far, we have been discussing what are known as feedforward neural networks. However, there are variations on this that are worth describing as different kinds of neural networks are used for different kinds of tasks, including image recognition, natural language processing, and time series analysis. There are three main types of neural networks: feedforward, convolutional, and recurrent networks.</p>
<section id="feedforward-neural-networks-fnns" class="level4">
<h4 class="anchored" data-anchor-id="feedforward-neural-networks-fnns">Feedforward Neural Networks (FNNs)</h4>
<ul>
<li><em>Description</em>: Feedforward neural networks are the simplest type of neural network. They consist of an input layer, one or more hidden layers, and an output layer. Information flows in one direction, from input to output, without cycles or loops.</li>
<li><em>Use Cases</em>: FNNs are commonly used for tasks like classification and regression.</li>
<li><em>Advantages</em>: Easy to implement, work well for structured data.</li>
<li><em>Disadvantages</em>: Limited for tasks involving sequences or spatial data.</li>
</ul>
</section>
<section id="convolutional-neural-networks-cnns" class="level4">
<h4 class="anchored" data-anchor-id="convolutional-neural-networks-cnns">Convolutional Neural Networks (CNNs)</h4>
<ul>
<li><em>Description</em>: Convolutional neural networks are designed for tasks involving grid-like data, such as images. They use convolutional layers to automatically learn and detect features at different spatial hierarchies.</li>
<li><em>Use Cases</em>: CNNs excel at image classification, object detection, and segmentation.</li>
<li><em>Advantages</em>: Hierarchical feature learning, translational invariance.</li>
<li><em>Disadvantages</em>: May require substantial data, computationally intensive.</li>
</ul>
</section>
<section id="recurrent-neural-networks-rnns" class="level4">
<h4 class="anchored" data-anchor-id="recurrent-neural-networks-rnns">Recurrent Neural Networks (RNNs)</h4>
<ul>
<li><em>Description</em>: Recurrent neural networks are specialized for sequence data. They use recurrent connections to maintain memory of previous inputs. This enables tasks that depend on sequence context.</li>
<li><em>Use Cases</em>: RNNs are used for tasks like time series prediction, speech recognition, and natural language processing.</li>
<li><em>Advantages</em>: Sequence modeling, dynamic context understanding.</li>
<li><em>Disadvantages</em>: Vulnerable to vanishing gradients, limited memory.</li>
</ul>
</section>
<section id="comparison-and-contrast" class="level4">
<h4 class="anchored" data-anchor-id="comparison-and-contrast">Comparison and Contrast</h4>
<ul>
<li><em>Data Type</em>: FNNs work well with structured data, while CNNs are designed for grid-like data (e.g., images), and RNNs are for sequential data.</li>
<li><em>Architecture</em>: FNNs have no internal memory or feedback loops, while RNNs maintain memory through recurrent connections. CNNs have convolutional layers for feature extraction.</li>
<li><em>Applications</em>: FNNs are suitable for tabular data, CNNs for image-related tasks, and RNNs for sequences (text, time series).</li>
<li><em>Training</em>: FNNs are typically trained via backpropagation, CNNs leverage convolutional filters, and RNNs use backpropagation through time (BPTT).</li>
</ul>
<p>Each type of neural network is tailored to specific data types and tasks. The choice of network architecture depends on the problem at hand, and in some cases, hybrid models may be used to leverage the strengths of multiple network types.</p>
</section>
</section>
<section id="convolutional-neural-networks-cnns-1" class="level3">
<h3 class="anchored" data-anchor-id="convolutional-neural-networks-cnns-1">Convolutional Neural Networks (CNNs)</h3>
<p>Convolutional Neural Networks (CNNs) are a type of neural network designed for processing grid-like data, with a primary focus on tasks related to images and other spatial data. CNNs have been instrumental in revolutionizing computer vision and are widely used for tasks like image classification, object detection, and segmentation.</p>
<section id="architecture-of-cnns" class="level4">
<h4 class="anchored" data-anchor-id="architecture-of-cnns">Architecture of CNNs</h4>
<p>CNNs are characterized by a unique architecture that is well-suited for extracting features from grid-like data:</p>
<ol type="1">
<li><p><strong>Convolutional Layers</strong>: These layers are responsible for feature extraction. They consist of learnable filters (kernels) that scan the input data, capturing local patterns. Convolutional layers create feature maps that highlight relevant spatial features.</p></li>
<li><p><strong>Pooling Layers</strong>: Pooling layers reduce the spatial dimensions of the feature maps, decreasing the computational load. Max pooling is a common approach where the maximum value in a local region is retained.</p></li>
<li><p><strong>Fully Connected Layers</strong>: After feature extraction, CNNs often have one or more fully connected layers similar to those in feedforward networks. These layers combine the features to make predictions.</p></li>
</ol>
</section>
<section id="training-process-for-cnns" class="level4">
<h4 class="anchored" data-anchor-id="training-process-for-cnns">Training Process for CNNs</h4>
<p>The training process for CNNs involves the following key steps:</p>
<ol type="1">
<li><p><strong>Initialization</strong>: Weights and biases in the network are initialized, typically with small random values.</p></li>
<li><p><strong>Forward Propagation</strong>: During forward propagation, input data is passed through the network. Convolutional and pooling layers extract features, while fully connected layers produce predictions.</p></li>
<li><p><strong>Loss Calculation</strong>: A loss function is used to measure the difference between the predicted values and the ground truth. Common loss functions include cross-entropy for classification tasks.</p></li>
<li><p><strong>Backpropagation</strong>: During backpropagation, gradients are computed with respect to the loss. Gradients are used to adjust the network’s weights and biases in a direction that minimizes the loss.</p></li>
<li><p><strong>Optimization</strong>: Various optimization algorithms, like stochastic gradient descent (SGD) or its variants (e.g., Adam), are used to update the network’s parameters. The learning rate determines the size of weight updates.</p></li>
<li><p><strong>Training Loop</strong>: Steps 2 to 5 are repeated iteratively for a fixed number of epochs or until convergence. Mini-batch training is common, where the data is divided into small batches for more efficient training.</p></li>
</ol>
</section>
<section id="cnns-in-practice" class="level4">
<h4 class="anchored" data-anchor-id="cnns-in-practice">CNNs in Practice</h4>
<p>In practice, CNNs are often pre-trained on large datasets (e.g., ImageNet) to learn useful feature representations. Transfer learning allows fine-tuning these pre-trained models for specific tasks, reducing the need for large datasets.</p>
<p>The success of CNNs can be attributed to their ability to automatically learn hierarchical features from raw data. They excel at capturing patterns in different spatial hierarchies, making them suitable for a wide range of computer vision tasks.</p>
</section>
</section>
<section id="recurrent-neural-networks-rnns-1" class="level3">
<h3 class="anchored" data-anchor-id="recurrent-neural-networks-rnns-1">Recurrent Neural Networks (RNNs)</h3>
<p>Recurrent Neural Networks (RNNs) are a type of neural network specially designed for sequential data and tasks that depend on maintaining memory of previous inputs. RNNs have been widely used in natural language processing, time series analysis, speech recognition, and more.</p>
<section id="architecture-of-rnns" class="level4">
<h4 class="anchored" data-anchor-id="architecture-of-rnns">Architecture of RNNs</h4>
<p>RNNs are characterized by their recurrent connections, which enable the network to maintain memory across time steps. The basic architecture of an RNN consists of the following components:</p>
<ol type="1">
<li><p><strong>Hidden State</strong>: At each time step, an RNN maintains a hidden state that serves as a memory of past inputs and computations.</p></li>
<li><p><strong>Recurrent Connection</strong>: The hidden state at the current time step is computed based on the input at the current time step and the hidden state at the previous time step. This recurrent connection allows RNNs to capture dependencies across sequential data.</p></li>
<li><p><strong>Output Layer</strong>: RNNs can have an output layer, which produces predictions or features based on the current hidden state. The output can be used for various tasks, such as sequence classification or prediction.</p></li>
</ol>
</section>
<section id="training-process-for-rnns" class="level4">
<h4 class="anchored" data-anchor-id="training-process-for-rnns">Training Process for RNNs</h4>
<p>The training process for RNNs involves the following key steps:</p>
<ol type="1">
<li><p><strong>Initialization</strong>: Weights and biases in the network are initialized, typically with small random values.</p></li>
<li><p><strong>Forward Propagation</strong>: During forward propagation, input data is passed through the network one time step at a time. The hidden state is updated at each time step based on the input and the previous hidden state.</p></li>
<li><p><strong>Loss Calculation</strong>: A loss function is used to measure the difference between the predicted values and the ground truth. Common loss functions include mean squared error for regression tasks and cross-entropy for classification tasks.</p></li>
<li><p><strong>Backpropagation Through Time (BPTT)</strong>: BPTT is a variant of backpropagation used to compute gradients through time. It involves calculating gradients of the loss with respect to the network’s parameters, considering all time steps.</p></li>
<li><p><strong>Optimization</strong>: Gradients are used to adjust the network’s weights and biases using optimization algorithms like stochastic gradient descent (SGD) or its variants.</p></li>
<li><p><strong>Training Loop</strong>: Steps 2 to 5 are repeated iteratively for a fixed number of time steps or until convergence. Mini-batch training is common, where the data is divided into small batches for more efficient training.</p></li>
</ol>
</section>
<section id="rnns-in-practice" class="level4">
<h4 class="anchored" data-anchor-id="rnns-in-practice">RNNs in Practice</h4>
<p>In practice, RNNs may face challenges like vanishing gradients, where gradients become extremely small and hinder the training process. To address this, variants of RNNs, such as Long Short-Term Memory (LSTM) and Gated Recurrent Unit (GRU), have been developed with more sophisticated gating mechanisms.</p>
<p>RNNs are effective for tasks that involve sequential data, as they can capture dependencies and temporal patterns. They have been widely used for natural language processing, including tasks like language modeling, machine translation, and sentiment analysis.</p>
<p>Despite their effectiveness, RNNs may be computationally expensive and may not scale well to very long sequences. In such cases, alternatives like attention mechanisms or Transformers have gained popularity.</p>
</section>
</section>
</section>
<section id="neural-networks-in-r" class="level2">
<h2 class="anchored" data-anchor-id="neural-networks-in-r"><svg viewbox="0 0 581 512" style="position:relative;display:inline-block;top:.1em;fill:steelblue;height:2em;" xmlns="http://www.w3.org/2000/svg"> <path d="M581 226.6C581 119.1 450.9 32 290.5 32S0 119.1 0 226.6C0 322.4 103.3 402 239.4 418.1V480h99.1v-61.5c24.3-2.7 47.6-7.4 69.4-13.9L448 480h112l-67.4-113.7c54.5-35.4 88.4-84.9 88.4-139.7zm-466.8 14.5c0-73.5 98.9-133 220.8-133s211.9 40.7 211.9 133c0 50.1-26.5 85-70.3 106.4-2.4-1.6-4.7-2.9-6.4-3.7-10.2-5.2-27.8-10.5-27.8-10.5s86.6-6.4 86.6-92.7-90.6-87.9-90.6-87.9h-199V361c-74.1-21.5-125.2-67.1-125.2-119.9zm225.1 38.3v-55.6c57.8 0 87.8-6.8 87.8 27.3 0 36.5-38.2 28.3-87.8 28.3zm-.9 72.5H365c10.8 0 18.9 11.7 24 19.2-16.1 1.9-33 2.8-50.6 2.9v-22.1z"></path></svg> Neural Networks in R</h2>
<p>We have already seen one example of training a neural network in R using the <code>brulee</code> package which fits in with the <code>tidymodels</code> framework. There are another of other packages which facilitate deep learning in R and it is worth being aware of them since some of them allow one to go beyond what is capable with <code>brulee</code> and implement CNNs or RNNs.</p>
<section id="r-packages-for-neural-networks-and-deep-learning" class="level3">
<h3 class="anchored" data-anchor-id="r-packages-for-neural-networks-and-deep-learning">R Packages for Neural Networks and Deep Learning</h3>
<ol type="1">
<li><strong>keras:</strong>
<ul>
<li><em>Description</em>: The <code>keras</code> package in R provides an interface to the Keras deep learning framework. Keras is known for its ease of use and flexibility and can run on top of TensorFlow, Theano, or Microsoft Cognitive Toolkit (CNTK).</li>
<li><em>Documentation</em>: <a href="https://keras.rstudio.com/">keras Documentation</a></li>
<li><em>Tutorials</em>: <a href="https://keras.rstudio.com/articles/tutorial_basic_classification.html">keras Tutorials</a></li>
<li><em>Lab from Textbook</em>: The webpage for the ISLR2 textbook contains a link to a lab that uses the <code>keras</code> package. <a href="https://hastie.su.domains/ISLR2/Labs/Rmarkdown_Notebooks/Ch10-deeplearning-lab-keras.html">View lab</a>.</li>
</ul></li>
<li><strong>tensorflow:</strong>
<ul>
<li><em>Description</em>: The <code>tensorflow</code> package for R provides a low-level interface to the TensorFlow deep learning framework. It allows for fine-grained control over model architecture and training.</li>
<li><em>Documentation</em>: <a href="https://tensorflow.rstudio.com/">tensorflow Documentation</a></li>
<li><em>Tutorials</em>: <a href="https://tensorflow.rstudio.com/tutorials/beginners/basic-ml/tutorial_basic_classification/">tensorflow Tutorials</a></li>
</ul></li>
<li><strong>torch:</strong>
<ul>
<li><em>Description</em>: The <code>torch</code> package offers an interface to PyTorch, a deep learning framework known for its flexibility and dynamic computation graph. It is suitable for both research and production.</li>
<li><em>Documentation</em>: <a href="https://torch.mlverse.org/">torch Documentation</a></li>
<li><em>Textbook</em>: <a href="https://skeydan.github.io/Deep-Learning-and-Scientific-Computing-with-R-torch/">Deep Learning and Scientific Computing with R</a></li>
<li><em>Lab from Textbook</em>: The webpage for the ISLR2 textbook contains a link to a lab that uses the <code>torch</code> package. <a href="https://hastie.su.domains/ISLR2/Labs/Rmarkdown_Notebooks/Ch10-deeplearning-lab-torch.html">View lab</a>.</li>
</ul></li>
<li><strong>caret:</strong>
<ul>
<li><em>Description</em>: While not a deep learning library, the <code>caret</code> package is a versatile tool for training and evaluating machine learning models, including neural networks. It provides a unified interface for various R packages and algorithms.</li>
<li><em>Documentation</em>: <a href="https://topepo.github.io/caret/">caret Documentation</a></li>
</ul></li>
<li><strong>h2o:</strong>
<ul>
<li><em>Description</em>: The <code>h2o</code> package is designed for scalable machine learning and deep learning. It provides an easy-to-use interface for building deep learning models, autoML, and more.</li>
<li><em>Documentation</em>: <a href="http://docs.h2o.ai/h2o/latest-stable/h2o-docs/booklets/DeepLearningBooklet.pdf">h2o Documentation</a></li>
</ul></li>
</ol>
<p>These R packages cover a range of deep learning needs, from high-level and user-friendly interfaces to low-level control and flexibility. Explore the provided documentation and tutorials to get started with deep learning using these tools.</p>
</section>
</section>
<section id="further-topics-on-deep-learning" class="level2">
<h2 class="anchored" data-anchor-id="further-topics-on-deep-learning">Further Topics on Deep Learning</h2>
<p>This is some further information on neural networks and deep learning based on questions raised by students.</p>
<section id="recent-applications-of-neural-networks-and-deep-learning" class="level3">
<h3 class="anchored" data-anchor-id="recent-applications-of-neural-networks-and-deep-learning">Recent Applications of Neural Networks and Deep Learning</h3>
<ol type="1">
<li><strong>Natural Language Processing (NLP):</strong>
<ul>
<li><em>Example</em>: BERT, GPT-3, and other large transformer models for tasks like language translation, text generation, and sentiment analysis.</li>
<li><em>Learn More</em>: <a href="https://openai.com/research/gpt-3">OpenAI’s GPT-3</a>, <a href="https://ai.google/research/pubs/pub48095">Google’s BERT</a></li>
</ul></li>
<li><strong>Computer Vision:</strong>
<ul>
<li><em>Example</em>: Convolutional Neural Networks (CNNs) for image classification, object detection, and facial recognition.</li>
<li><em>Learn More</em>: <a href="http://www.image-net.org/challenges/LSVRC/">ImageNet Large Scale Visual Recognition Challenge</a></li>
</ul></li>
<li><strong>Healthcare:</strong>
<ul>
<li><em>Example</em>: Using deep learning to analyze medical images, detect diseases, and predict patient outcomes.</li>
<li><em>Learn More</em>: <a href="https://stanfordmlgroup.github.io/projects/chexnet/">Stanford’s CheXNet</a></li>
</ul></li>
<li><strong>Autonomous Vehicles:</strong>
<ul>
<li><em>Example</em>: Self-driving cars rely on neural networks to perceive their surroundings and make decisions.</li>
<li><em>Learn More</em>: <a href="https://waymo.com/technology/">Waymo’s Self-Driving Technology</a></li>
</ul></li>
<li><strong>Recommender Systems:</strong>
<ul>
<li><em>Example</em>: Recommending products, movies, or content to users based on their preferences and behavior.</li>
<li><em>Learn More</em>: <a href="https://help.netflix.com/en/node/100639">Netflix’s Recommendation Algorithm</a></li>
</ul></li>
<li><strong>Finance:</strong>
<ul>
<li><em>Example</em>: Predictive modeling for stock price forecasting, fraud detection, and algorithmic trading.</li>
<li><em>Learn More</em>: <a href="https://github.com/mwitiderrick/stockprice">Stock Price Prediction with LSTM</a></li>
</ul></li>
<li><strong>Voice Assistants:</strong>
<ul>
<li><em>Example</em>: Voice recognition and natural language understanding in smart speakers like Amazon Echo and Google Home.</li>
<li><em>Learn More</em>: <a href="https://developer.amazon.com/en-US/alexa">Amazon Alexa</a></li>
</ul></li>
<li><strong>Generative Adversarial Networks (GANs):</strong>
<ul>
<li><em>Example</em>: Creating art, generating synthetic images, and deepfakes.</li>
<li><em>Learn More</em>: <a href="https://www.nvidia.com/en-us/research/ai-playground/">NVIDIA’s GAN Research</a></li>
</ul></li>
<li><strong>Robotics:</strong>
<ul>
<li><em>Example</em>: Deep reinforcement learning for robot control and autonomous navigation.</li>
<li><em>Learn More</em>: <a href="https://openai.com/research/robotics">OpenAI’s Robotics Research</a></li>
</ul></li>
<li><strong>Climate Science:</strong>
<ul>
<li><em>Example</em>: Using neural networks to analyze climate data, model climate change, and predict extreme weather events.</li>
<li><em>Learn More</em>: <a href="https://deepmind.com/research/case-studies/climate-change">DeepMind’s Climate Science</a></li>
</ul></li>
</ol>
</section>
<section id="sizes-of-neural-networks-in-various-applications" class="level3">
<h3 class="anchored" data-anchor-id="sizes-of-neural-networks-in-various-applications">Sizes of Neural Networks in Various Applications</h3>
<ol type="1">
<li><strong>Natural Language Processing (NLP):</strong>
<ul>
<li><em>GPT-3</em>: GPT-3, developed by OpenAI, is one of the largest language models with 175 billion parameters.</li>
<li><em>BERT</em>: Google’s BERT has 340 million parameters and is highly influential in NLP.</li>
</ul></li>
<li><strong>Computer Vision:</strong>
<ul>
<li><em>ImageNet Models</em>: Models like VGG-16, VGG-19, and ResNet used for image classification have tens of millions of parameters.</li>
<li><em>Large CNNs</em>: In complex computer vision tasks, models can have hundreds of millions of parameters. Examples include Inception models and DenseNet.</li>
</ul></li>
<li><strong>Healthcare:</strong>
<ul>
<li>The size of neural networks in healthcare applications varies, ranging from a few million to tens of millions of parameters for tasks like medical image analysis.</li>
</ul></li>
<li><strong>Autonomous Vehicles:</strong>
<ul>
<li>Neural networks used in autonomous vehicles vary in size. Perception networks processing sensor data may have tens of millions of parameters, while decision-making networks might be smaller.</li>
</ul></li>
<li><strong>Generative Adversarial Networks (GANs):</strong>
<ul>
<li>Large GANs, such as BigGAN, can have hundreds of millions of parameters and are used for image generation.</li>
</ul></li>
<li><strong>Climate Science:</strong>
<ul>
<li>Climate models using deep learning can have varying numbers of parameters, typically in the millions to tens of millions, depending on the model’s complexity.</li>
</ul></li>
</ol>
</section>
<section id="choosing-depth-and-width-of-neural-networks" class="level3">
<h3 class="anchored" data-anchor-id="choosing-depth-and-width-of-neural-networks">Choosing Depth and Width of Neural Networks</h3>
<p>Selecting the appropriate depth and width of neural networks is a crucial decision in deep learning. Here are common techniques and considerations for making this choice:</p>
<ol type="1">
<li><strong>Model Complexity vs.&nbsp;Data Size:</strong>
<ul>
<li>Consider the balance between the model’s complexity and the size of the available data. Smaller datasets may benefit from simpler, shallower networks, while larger datasets can support deeper and wider architectures.</li>
</ul></li>
<li><strong>Empirical Exploration:</strong>
<ul>
<li>Start with a basic architecture and experiment with deeper or wider networks to find the optimal balance. This involves training and evaluating different architectures to identify the best-performing one for the task.</li>
</ul></li>
<li><strong>Regularization Techniques:</strong>
<ul>
<li>Implement techniques like dropout, weight decay (L2 regularization), and batch normalization to prevent overfitting, enabling deeper networks without sacrificing generalization performance.</li>
</ul></li>
<li><strong>Transfer Learning:</strong>
<ul>
<li>For certain applications, consider transfer learning from pretrained models. Fine-tuning a pretrained model may require fewer layers and parameters, saving training time.</li>
</ul></li>
<li><strong>Architectural Variations:</strong>
<ul>
<li>Explore different architectural variations, such as the number of layers, hidden units, and filter sizes. Techniques like grid search or random search can be employed to discover promising architectures.</li>
</ul></li>
<li><strong>Architectural Search Algorithms:</strong>
<ul>
<li>Utilize automated neural architecture search (NAS) algorithms, including reinforcement learning-based methods and evolutionary algorithms, to discover optimal neural network architectures automatically.</li>
</ul></li>
<li><strong>Model Size and Computational Resources:</strong>
<ul>
<li>Be mindful of computational resources when choosing the depth and width. Deeper and wider models demand more training time and memory.</li>
</ul></li>
<li><strong>Task Complexity:</strong>
<ul>
<li>The complexity of the task can guide architectural decisions. Simple tasks may require shallower networks, while complex tasks may benefit from deeper and wider architectures.</li>
</ul></li>
<li><strong>Pruning and Quantization:</strong>
<ul>
<li>After training, apply pruning or quantization techniques to reduce the size and complexity of trained models without sacrificing performance.</li>
</ul></li>
<li><strong>Ensemble Methods:</strong>
<ul>
<li>Consider using ensemble methods that combine predictions from multiple neural networks with different architectures to enhance overall performance.</li>
</ul></li>
<li><strong>Domain Expertise:</strong>
<ul>
<li>Knowledge of the domain and task can guide architectural choices. For example, specific data types, like sequential data in NLP, may benefit from recurrent or attention-based architectures.</li>
</ul></li>
<li><strong>Validation and Cross-Validation:</strong>
<ul>
<li>Leverage cross-validation and validation performance metrics to identify the appropriate trade-off between model capacity and generalization.</li>
</ul></li>
</ol>
<p>The choice of architecture often involves a trade-off between model capacity and the risk of overfitting. Experimentation may be required to determine the ideal architecture for a particular task. The deep learning field continues to evolve, offering new techniques and tools to assist with architecture selection.</p>
</section>
</section>
<section id="freely-available-libraries-and-packages-for-neural-networks" class="level2">
<h2 class="anchored" data-anchor-id="freely-available-libraries-and-packages-for-neural-networks">Freely Available Libraries and Packages for Neural Networks</h2>
<section id="other-languages" class="level3">
<h3 class="anchored" data-anchor-id="other-languages">Other Languages</h3>
<ol type="1">
<li><strong>TensorFlow:</strong>
<ul>
<li><em>Description</em>: TensorFlow is an open-source deep learning framework by Google, widely used for building and training neural networks.</li>
<li><em>Documentation</em>: <a href="https://www.tensorflow.org/">TensorFlow Official Documentation</a></li>
<li><em>Tutorials</em>: <a href="https://www.tensorflow.org/tutorials">TensorFlow Tutorials</a></li>
</ul></li>
<li><strong>Keras:</strong>
<ul>
<li><em>Description</em>: Keras is a high-level neural networks API that runs on top of TensorFlow and other frameworks, simplifying model building.</li>
<li><em>Documentation</em>: <a href="https://keras.io/">Keras Official Documentation</a></li>
<li><em>Tutorials</em>: <a href="https://keras.io/getting_started/intro_to_keras_for_engineers/">Keras Tutorials</a></li>
</ul></li>
<li><strong>PyTorch:</strong>
<ul>
<li><em>Description</em>: PyTorch is a deep learning framework known for its flexibility and dynamic computation graph, ideal for research and development.</li>
<li><em>Documentation</em>: <a href="https://pytorch.org/docs/stable/index.html">PyTorch Official Documentation</a></li>
<li><em>Tutorials</em>: <a href="https://pytorch.org/tutorials/">PyTorch Tutorials</a></li>
</ul></li>
<li><strong>scikit-learn:</strong>
<ul>
<li><em>Description</em>: While primarily focused on traditional machine learning, scikit-learn offers neural network capabilities for integration with other machine learning tasks.</li>
<li><em>Documentation</em>: <a href="https://scikit-learn.org/stable/documentation.html">scikit-learn Official Documentation</a></li>
<li><em>Tutorials</em>: <a href="https://scikit-learn.org/stable/modules/neural_networks_supervised.html">scikit-learn Neural Networks Guide</a></li>
</ul></li>
<li><strong>Fastai:</strong>
<ul>
<li><em>Description</em>: Fastai is a high-level deep learning library built on PyTorch, designed to make deep learning more accessible for practitioners.</li>
<li><em>Documentation</em>: <a href="https://docs.fast.ai/">Fastai Documentation</a></li>
<li><em>Tutorials</em>: <a href="https://docs.fast.ai/tutorial.html">Fastai Tutorials</a></li>
</ul></li>
<li><strong>Flux.jl:</strong>
<ul>
<li><em>Description</em>: Flux is a widely used deep learning library in Julia known for its simplicity and flexibility. It provides a user-friendly API for defining and training neural networks.</li>
<li><em>Documentation</em>: <a href="https://fluxml.ai/Flux.jl/stable/">Flux.jl Documentation</a></li>
</ul></li>
<li><strong>Knet.jl:</strong>
<ul>
<li><em>Description</em>: Knet (pronounced “kay-net”) is a deep learning framework that aims to be as fast and efficient as possible. It’s suitable for both research and production use.</li>
<li><em>Documentation</em>: <a href="https://denizyuret.github.io/Knet.jl/stable/">Knet.jl Documentation</a></li>
</ul></li>
</ol>
<p>These libraries and packages offer diverse capabilities and features for implementing and training neural networks. Explore the provided documentation and tutorials to get started with deep learning using these tools.</p>
</section>
</section>
<section id="references" class="level2">
<h2 class="anchored" data-anchor-id="references">References</h2>
<div id="refs" class="references csl-bib-body hanging-indent" role="list">
<div id="ref-deisenroth2020mathematics" class="csl-entry" role="listitem">
Deisenroth, Marc Peter, A Aldo Faisal, and Cheng Soon Ong. 2020. <em>Mathematics for Machine Learning</em>. Cambridge University Press.
</div>
<div id="ref-Goodfellow-et-al-2016" class="csl-entry" role="listitem">
Goodfellow, Ian, Yoshua Bengio, and Aaron Courville. 2016. <em>Deep Learning</em>. MIT Press.
</div>
<div id="ref-krohn2019deep" class="csl-entry" role="listitem">
Krohn, Jon, Grant Beyleveld, and Aglaé Bassens. 2019. <em>Deep Learning Illustrated</em>. Addison-Wesley Professional.
</div>
<div id="ref-tibshirani2017introduction" class="csl-entry" role="listitem">
Tibshirani, Hastie Robert, Gareth James, and Daniela Witten Trevor. 2017. <em>An Introduction to Statistical Learning</em>. springer publication.
</div>
</div>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-1-contents" aria-controls="callout-1" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Expand for Session Info
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-1" class="callout-1-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<div class="cell">
<div class="cell-output cell-output-stdout">
<pre><code>─ Session info ───────────────────────────────────────────────────────────────
 setting  value
 version  R version 4.3.1 (2023-06-16)
 os       macOS Sonoma 14.0
 system   aarch64, darwin20
 ui       X11
 language (EN)
 collate  en_US.UTF-8
 ctype    en_US.UTF-8
 tz       America/New_York
 date     2023-10-18
 pandoc   3.1.8 @ /opt/homebrew/bin/ (via rmarkdown)
 quarto   1.3.450 @ /usr/local/bin/quarto

─ Packages ───────────────────────────────────────────────────────────────────
 package      * version date (UTC) lib source
 broom        * 1.0.5   2023-06-09 [1] CRAN (R 4.3.0)
 dials        * 1.2.0   2023-04-03 [1] CRAN (R 4.3.0)
 dplyr        * 1.1.3   2023-09-03 [1] CRAN (R 4.3.0)
 forcats      * 1.0.0   2023-01-29 [1] CRAN (R 4.3.0)
 ggplot2      * 3.4.4   2023-10-12 [1] CRAN (R 4.3.1)
 infer        * 1.0.5   2023-09-06 [1] CRAN (R 4.3.0)
 latex2exp    * 0.9.6   2022-11-28 [1] CRAN (R 4.3.0)
 lubridate    * 1.9.3   2023-09-27 [1] CRAN (R 4.3.1)
 modeldata    * 1.2.0   2023-08-09 [1] CRAN (R 4.3.0)
 parsnip      * 1.1.1   2023-08-17 [1] CRAN (R 4.3.0)
 purrr        * 1.0.2   2023-08-10 [1] CRAN (R 4.3.0)
 readr        * 2.1.4   2023-02-10 [1] CRAN (R 4.3.0)
 recipes      * 1.0.8   2023-08-25 [1] CRAN (R 4.3.0)
 rsample      * 1.2.0   2023-08-23 [1] CRAN (R 4.3.0)
 scales       * 1.2.1   2022-08-20 [1] CRAN (R 4.3.0)
 sessioninfo  * 1.2.2   2021-12-06 [1] CRAN (R 4.3.0)
 stringr      * 1.5.0   2022-12-02 [1] CRAN (R 4.3.0)
 tibble       * 3.2.1   2023-03-20 [1] CRAN (R 4.3.0)
 tidymodels   * 1.1.1   2023-08-24 [1] CRAN (R 4.3.0)
 tidyr        * 1.3.0   2023-01-24 [1] CRAN (R 4.3.0)
 tidyverse    * 2.0.0   2023-02-22 [1] CRAN (R 4.3.0)
 tune         * 1.1.2   2023-08-23 [1] CRAN (R 4.3.0)
 workflows    * 1.1.3   2023-02-22 [1] CRAN (R 4.3.0)
 workflowsets * 1.0.1   2023-04-06 [1] CRAN (R 4.3.0)
 yardstick    * 1.2.0   2023-04-21 [1] CRAN (R 4.3.0)

 [1] /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/library

──────────────────────────────────────────────────────────────────────────────</code></pre>
</div>
</div>
</div>
</div>
</div>
<div class="quarto-figure quarto-figure-left">
<figure class="figure">
<p><a href="https://creativecommons.org/licenses/by-nc-sa/4.0/legalcode"><img src="http://mirrors.creativecommons.org/presskit/buttons/88x31/png/by-nc-sa.png?raw=1" class="img-fluid figure-img" style="width:15.0%"></a></p>
</figure>
</div>


</section>

<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents"><h2 class="anchored quarto-appendix-heading">Reuse</h2><div id="quarto-reuse" class="quarto-appendix-contents"><div>CC BY-NC-SA 4.0</div></div></section></div></main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const disableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'prefetch';
    }
  }
  const enableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'stylesheet';
    }
  }
  const manageTransitions = (selector, allowTransitions) => {
    const els = window.document.querySelectorAll(selector);
    for (let i=0; i < els.length; i++) {
      const el = els[i];
      if (allowTransitions) {
        el.classList.remove('notransition');
      } else {
        el.classList.add('notransition');
      }
    }
  }
  const toggleColorMode = (alternate) => {
    // Switch the stylesheets
    const alternateStylesheets = window.document.querySelectorAll('link.quarto-color-scheme.quarto-color-alternate');
    manageTransitions('#quarto-margin-sidebar .nav-link', false);
    if (alternate) {
      enableStylesheet(alternateStylesheets);
      for (const sheetNode of alternateStylesheets) {
        if (sheetNode.id === "quarto-bootstrap") {
          toggleBodyColorMode(sheetNode);
        }
      }
    } else {
      disableStylesheet(alternateStylesheets);
      toggleBodyColorPrimary();
    }
    manageTransitions('#quarto-margin-sidebar .nav-link', true);
    // Switch the toggles
    const toggles = window.document.querySelectorAll('.quarto-color-scheme-toggle');
    for (let i=0; i < toggles.length; i++) {
      const toggle = toggles[i];
      if (toggle) {
        if (alternate) {
          toggle.classList.add("alternate");     
        } else {
          toggle.classList.remove("alternate");
        }
      }
    }
    // Hack to workaround the fact that safari doesn't
    // properly recolor the scrollbar when toggling (#1455)
    if (navigator.userAgent.indexOf('Safari') > 0 && navigator.userAgent.indexOf('Chrome') == -1) {
      manageTransitions("body", false);
      window.scrollTo(0, 1);
      setTimeout(() => {
        window.scrollTo(0, 0);
        manageTransitions("body", true);
      }, 40);  
    }
  }
  const isFileUrl = () => { 
    return window.location.protocol === 'file:';
  }
  const hasAlternateSentinel = () => {  
    let styleSentinel = getColorSchemeSentinel();
    if (styleSentinel !== null) {
      return styleSentinel === "alternate";
    } else {
      return false;
    }
  }
  const setStyleSentinel = (alternate) => {
    const value = alternate ? "alternate" : "default";
    if (!isFileUrl()) {
      window.localStorage.setItem("quarto-color-scheme", value);
    } else {
      localAlternateSentinel = value;
    }
  }
  const getColorSchemeSentinel = () => {
    if (!isFileUrl()) {
      const storageValue = window.localStorage.getItem("quarto-color-scheme");
      return storageValue != null ? storageValue : localAlternateSentinel;
    } else {
      return localAlternateSentinel;
    }
  }
  let localAlternateSentinel = 'default';
  // Dark / light mode switch
  window.quartoToggleColorScheme = () => {
    // Read the current dark / light value 
    let toAlternate = !hasAlternateSentinel();
    toggleColorMode(toAlternate);
    setStyleSentinel(toAlternate);
  };
  // Ensure there is a toggle, if there isn't float one in the top right
  if (window.document.querySelector('.quarto-color-scheme-toggle') === null) {
    const a = window.document.createElement('a');
    a.classList.add('top-right');
    a.classList.add('quarto-color-scheme-toggle');
    a.href = "";
    a.onclick = function() { try { window.quartoToggleColorScheme(); } catch {} return false; };
    const i = window.document.createElement("i");
    i.classList.add('bi');
    a.appendChild(i);
    window.document.body.appendChild(a);
  }
  // Switch to dark mode if need be
  if (hasAlternateSentinel()) {
    toggleColorMode(true);
  } else {
    toggleColorMode(false);
  }
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->



</body></html>