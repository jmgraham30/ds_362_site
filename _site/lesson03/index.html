<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.3.450">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="JMG">

<title>DS 362 - Lesson 3</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../site_libs/clipboard/clipboard.min.js"></script>
<script src="../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../site_libs/quarto-search/fuse.min.js"></script>
<script src="../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../">
<script src="../site_libs/quarto-html/quarto.js"></script>
<script src="../site_libs/quarto-html/popper.min.js"></script>
<script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../site_libs/quarto-html/anchor.min.js"></script>
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-text-highlighting-styles">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting-dark.css" rel="prefetch" class="quarto-color-scheme quarto-color-alternate" id="quarto-text-highlighting-styles">
<script src="../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-bootstrap" data-mode="light">
<link href="../site_libs/bootstrap/bootstrap-dark.min.css" rel="prefetch" class="quarto-color-scheme quarto-color-alternate" id="quarto-bootstrap" data-mode="dark">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<link href="../site_libs/vembedr-0.1.5/css/vembedr.css" rel="stylesheet">

  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<link rel="stylesheet" href="../styles.css">
</head>

<body class="floating nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg navbar-dark ">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container">
    <a class="navbar-brand" href="../index.html">
    <span class="navbar-title">DS 362</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link" href="../index.html" rel="" target="">
 <span class="menu-text">Home</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../syllabus.html" rel="" target="">
 <span class="menu-text">Syllabus</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../links.html" rel="" target="">
 <span class="menu-text">Links</span></a>
  </li>  
</ul>
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/jmgraham30/ds_362_site" rel="" target=""><i class="bi bi-github" role="img" aria-label="GitHub">
</i> 
 <span class="menu-text"></span></a>
  </li>  
</ul>
            <div class="quarto-navbar-tools">
  <a href="" class="quarto-color-scheme-toggle quarto-navigation-tool  px-1" onclick="window.quartoToggleColorScheme(); return false;" title="Toggle dark mode"><i class="bi"></i></a>
</div>
          </div> <!-- /navcollapse -->
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal sidebar-navigation floating overflow-auto">
    <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#learning-objectives" id="toc-learning-objectives" class="nav-link active" data-scroll-target="#learning-objectives">Learning Objectives</a></li>
  <li><a href="#readings-etc." id="toc-readings-etc." class="nav-link" data-scroll-target="#readings-etc.">Readings, etc.</a></li>
  <li><a href="#motivation-for-linear-regression" id="toc-motivation-for-linear-regression" class="nav-link" data-scroll-target="#motivation-for-linear-regression">Motivation for Linear Regression</a></li>
  <li><a href="#overdetermined-linear-systems-and-qr-factorization" id="toc-overdetermined-linear-systems-and-qr-factorization" class="nav-link" data-scroll-target="#overdetermined-linear-systems-and-qr-factorization">Overdetermined Linear Systems and <span class="math inline">\(QR\)</span> Factorization</a>
  <ul class="collapse">
  <li><a href="#norms-a-technical-tool" id="toc-norms-a-technical-tool" class="nav-link" data-scroll-target="#norms-a-technical-tool">Norms: A Technical Tool</a></li>
  <li><a href="#linear-regression-and-linear-least-squares" id="toc-linear-regression-and-linear-least-squares" class="nav-link" data-scroll-target="#linear-regression-and-linear-least-squares">Linear Regression and Linear Least Squares</a></li>
  <li><a href="#qr-factorization" id="toc-qr-factorization" class="nav-link" data-scroll-target="#qr-factorization"><span class="math inline">\(QR\)</span> Factorization</a></li>
  </ul></li>
  <li><a href="#simple-linear-regression" id="toc-simple-linear-regression" class="nav-link" data-scroll-target="#simple-linear-regression">Simple Linear Regression</a>
  <ul class="collapse">
  <li><a href="#an-example" id="toc-an-example" class="nav-link" data-scroll-target="#an-example">An Example</a></li>
  <li><a href="#fitting-linear-models-with-r" id="toc-fitting-linear-models-with-r" class="nav-link" data-scroll-target="#fitting-linear-models-with-r">Fitting Linear Models with R</a></li>
  </ul></li>
  <li><a href="#multiple-linear-regression" id="toc-multiple-linear-regression" class="nav-link" data-scroll-target="#multiple-linear-regression">Multiple Linear Regression</a></li>
  <li><a href="#linear-regression-in-machine-learning" id="toc-linear-regression-in-machine-learning" class="nav-link" data-scroll-target="#linear-regression-in-machine-learning">Linear Regression in Machine Learning</a></li>
  <li><a href="#preparation-for-the-next-lesson" id="toc-preparation-for-the-next-lesson" class="nav-link" data-scroll-target="#preparation-for-the-next-lesson">Preparation for the next lesson</a></li>
  <li><a href="#references" id="toc-references" class="nav-link" data-scroll-target="#references">References</a></li>
  </ul>
</nav>
</nav>
<div id="quarto-sidebar-glass" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">Lesson 3</h1>
<p class="subtitle lead">Linear Regression</p>
</div>



<div class="quarto-title-meta">

    <div>
    <div class="quarto-title-meta-heading">Author</div>
    <div class="quarto-title-meta-contents">
             <p>JMG </p>
          </div>
  </div>
    
  
    
  </div>
  

</header>

<section id="learning-objectives" class="level2">
<h2 class="anchored" data-anchor-id="learning-objectives">Learning Objectives</h2>
<p>After this lesson, students will be able to:</p>
<ul>
<li><p>Define linear regression and appreciate it from the perspective of machine learning.</p></li>
<li><p>Define the norm of a vector.</p></li>
<li><p>Understand the role of systems of linear equations, matrices, and <span class="math inline">\(QR\)</span> factorization in linear regression.</p></li>
<li><p>Use R to compute the <span class="math inline">\(QR\)</span> factorization of a matrix.</p></li>
<li><p>Use the <span class="math inline">\(QR\)</span> factorization to compute the coefficients for linear regression.</p></li>
</ul>
</section>
<section id="readings-etc." class="level2">
<h2 class="anchored" data-anchor-id="readings-etc.">Readings, etc.</h2>
<p>For this lesson:</p>
<ul>
<li><p>Read chapter 3 from of <em>An Introduction to Statistical Learning</em> <span class="citation" data-cites="tibshirani2017introduction">(<a href="#ref-tibshirani2017introduction" role="doc-biblioref">Tibshirani, James, and Trevor 2017</a>)</span>. You may also want to read chapter 2 of <em>Statistical Learning with Math and R</em> <span class="citation" data-cites="suzuki2020statistical">(<a href="#ref-suzuki2020statistical" role="doc-biblioref">Suzuki 2020</a>)</span>.</p></li>
<li><p>Watch the corresponding video lecture on regression. <a href="https://youtu.be/ox0cKk7h4o0">View on YouTube</a>.</p></li>
</ul>
<div class="cell">
<div class="cell-output-display">
<div class="vembedr" align="center">
<div>
<iframe src="https://www.youtube.com/embed/ox0cKk7h4o0" width="800" height="450" frameborder="0" allowfullscreen="" data-external="1"></iframe>
</div>
</div>
</div>
</div>
</section>
<section id="motivation-for-linear-regression" class="level2">
<h2 class="anchored" data-anchor-id="motivation-for-linear-regression">Motivation for Linear Regression</h2>
<p>Recall that in a supervised learning problem, we assume that there is a relationship between the predictor and response variables of the form:</p>
<p><span class="math display">\[
y = f({\bf x}) + \epsilon
\]</span> and then we seek to find a function <span class="math inline">\(\hat{f}\)</span> from a predetermined class of functions that does a good job in approximating <span class="math inline">\(f\)</span>. Let’s study this problem in more detail but in a very simplest setting. Specifically, we will assume that <span class="math inline">\({\bf x}\)</span> and <span class="math inline">\(y\)</span> are both single numerical variables and that <span class="math inline">\(f\)</span> is linear. Then writing everything out in detail, we assume that there are (true but unknown) numbers <span class="math inline">\(\beta_{0}\)</span> and <span class="math inline">\(\beta_{1}\)</span> such that</p>
<p><span class="math display">\[
y = \beta_{0} + \beta_{1} x + \epsilon
\]</span> for all values of <span class="math inline">\(x\)</span> and <span class="math inline">\(y\)</span>. Recall that we are assuming that <span class="math inline">\(\text{E}[\epsilon] = 0\)</span> so <span class="math inline">\(\epsilon\)</span> is a random variable with expected value (or mean) equal to zero.</p>
<p>If we restrict ourselves to the class of single-variable linear functions, then finding an approximation to <span class="math inline">\(f(x) = \beta_{0} + \beta_{1} x\)</span> is equivalent to finding values <span class="math inline">\(\hat{\beta}_0\)</span> and <span class="math inline">\(\hat{\beta}_{1}\)</span> so that</p>
<p><span class="math display">\[
\hat{f}(x) = \hat{\beta}_{0} + \hat{\beta}_{1} x \approx f(x) = \beta_{0} + \beta_{1} x
\]</span> Thus, this would be a <strong>parametric</strong> model since any candidate approximating function is uniquely specified by specifying the values for the parameters <span class="math inline">\(\hat{\beta}_0\)</span> and <span class="math inline">\(\hat{\beta}_{1}\)</span>.</p>
<p><a href="#fig-slr">Figure&nbsp;1</a> shows the plot of data that has been generated by a relationship of the form <span class="math inline">\(y = \beta_{0} + \beta_{1} x + \epsilon\)</span>. You should examine the code used to create or simulate the data in this example and see how it relates to the expression <span class="math inline">\(y = \beta_{0} + \beta_{1} x + \epsilon\)</span>.</p>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">1287</span>)</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a>N <span class="ot">&lt;-</span> <span class="dv">25</span></span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a>x <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(N,<span class="at">mean=</span><span class="dv">72</span>,<span class="at">sd=</span><span class="dv">12</span>)</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a>y <span class="ot">&lt;-</span> <span class="fl">1.2</span> <span class="sc">+</span> <span class="fl">0.75</span> <span class="sc">*</span> x <span class="sc">+</span> <span class="fu">rnorm</span>(N,<span class="at">sd=</span><span class="dv">2</span>)</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a>xy_data <span class="ot">&lt;-</span> <span class="fu">tibble</span>(<span class="at">x=</span>x,<span class="at">y=</span>y)</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a>xy_data <span class="sc">%&gt;%</span></span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>(<span class="fu">aes</span>(<span class="at">x=</span>x,<span class="at">y=</span>y)) <span class="sc">+</span> </span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display">
<div id="fig-slr" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="index_files/figure-html/fig-slr-1.png" class="img-fluid figure-img" width="672"></p>
<figcaption class="figure-caption">Figure&nbsp;1: A data set with two numerical variables <span class="math inline">\(x\)</span> and <span class="math inline">\(y\)</span> generated by an underlying linear function so that <span class="math inline">\(y = \beta_{0} + \beta_{1}x + \epsilon\)</span>.</figcaption>
</figure>
</div>
</div>
</div>
<p>From a (supervised) machine learning perspective, fitting a line to such data means “learning” the values of <span class="math inline">\(\hat{\beta}_0\)</span> and <span class="math inline">\(\hat{\beta}_{1}\)</span> from the data. How do we learn <span class="math inline">\(\hat{\beta}_0\)</span> and <span class="math inline">\(\hat{\beta}_{1}\)</span>? <a href="#fig-a-resid">Figure&nbsp;2</a> shows the same data as in <a href="#fig-slr">Figure&nbsp;1</a> but where we have added a best fit line as well as a single residual value.</p>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a>fitted_linear_model <span class="ot">&lt;-</span> <span class="fu">lm</span>(y <span class="sc">~</span> x, <span class="at">data=</span>xy_data) <span class="sc">%&gt;%</span></span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">augment</span>()</span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a>a_point <span class="ot">&lt;-</span> fitted_linear_model[<span class="dv">1</span>,<span class="dv">1</span><span class="sc">:</span><span class="dv">3</span>] <span class="sc">%&gt;%</span> <span class="fu">as.numeric</span>()</span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a>xy_data <span class="sc">%&gt;%</span></span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>(<span class="fu">aes</span>(<span class="at">x=</span>x,<span class="at">y=</span>y)) <span class="sc">+</span> </span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>() <span class="sc">+</span> </span>
<span id="cb2-9"><a href="#cb2-9" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_smooth</span>(<span class="at">method=</span><span class="st">"lm"</span>,<span class="at">se =</span> <span class="cn">FALSE</span>) <span class="sc">+</span> </span>
<span id="cb2-10"><a href="#cb2-10" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="at">data=</span><span class="cn">NULL</span>,<span class="fu">aes</span>(<span class="at">x=</span>a_point[<span class="dv">2</span>],<span class="at">y=</span>a_point[<span class="dv">3</span>]),<span class="at">color=</span><span class="st">"purple"</span>,<span class="at">size=</span><span class="dv">3</span>) <span class="sc">+</span> </span>
<span id="cb2-11"><a href="#cb2-11" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_segment</span>(<span class="fu">aes</span>(<span class="at">x =</span> a_point[<span class="dv">2</span>], <span class="at">y =</span> a_point[<span class="dv">1</span>], <span class="at">xend =</span> a_point[<span class="dv">2</span>], <span class="at">yend =</span> a_point[<span class="dv">3</span>]), </span>
<span id="cb2-12"><a href="#cb2-12" aria-hidden="true" tabindex="-1"></a>               <span class="at">data =</span> <span class="cn">NULL</span>,</span>
<span id="cb2-13"><a href="#cb2-13" aria-hidden="true" tabindex="-1"></a>               <span class="at">color=</span><span class="st">"red"</span>,<span class="at">lwd=</span><span class="dv">1</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display">
<div id="fig-a-resid" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="index_files/figure-html/fig-a-resid-1.png" class="img-fluid figure-img" width="672"></p>
<figcaption class="figure-caption">Figure&nbsp;2: The same data as shown in <a href="#fig-slr">Figure&nbsp;1</a> but with a best fit line as well as a single residual also shown.</figcaption>
</figure>
</div>
</div>
</div>
<p><a href="#fig-resids">Figure&nbsp;3</a> shows the same data as in <a href="#fig-slr">Figure&nbsp;1</a> but where we have added a best fit line as well as all the residual values. One way to learn the values for <span class="math inline">\(\hat{\beta}_0\)</span> and <span class="math inline">\(\hat{\beta}_{1}\)</span> is to minimize the squared error for the residuals.</p>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a>fitted_linear_model <span class="sc">%&gt;%</span></span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>(<span class="fu">aes</span>(<span class="at">x=</span>x,<span class="at">y=</span>y)) <span class="sc">+</span> </span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>() <span class="sc">+</span> </span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_smooth</span>(<span class="at">method=</span><span class="st">"lm"</span>,<span class="at">se =</span> <span class="cn">FALSE</span>) <span class="sc">+</span></span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_segment</span>(<span class="fu">aes</span>(<span class="at">x =</span> x, <span class="at">y =</span> y, <span class="at">xend =</span> x, <span class="at">yend =</span> .fitted), </span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a>               <span class="at">color=</span><span class="st">"red"</span>,<span class="at">lwd=</span><span class="dv">1</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display">
<div id="fig-resids" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="index_files/figure-html/fig-resids-1.png" class="img-fluid figure-img" width="672"></p>
<figcaption class="figure-caption">Figure&nbsp;3: The same data as shown in <a href="#fig-slr">Figure&nbsp;1</a> but with a best fit line as well as all residuals also shown.</figcaption>
</figure>
</div>
</div>
</div>
<p>Notice that we can write the squared error for the residuals as a function of two variables <span class="math inline">\(L(\beta_{0},\beta_{1})\)</span> defined by</p>
<p><span class="math display">\[
L(\beta_{0},\beta_{1}) = \sum_{i=1}^{n}(y_{i} - \beta_{0} - \beta_{1}x_{i})^2
\]</span></p>
<p>Then, in order to minimize this function we need to find the critical values for the function <span class="math inline">\(L\)</span> by computing partial derivatives and solving</p>
<p><span class="math display">\[
\begin{align*}
\frac{\partial L}{\partial \beta_{0}} &amp;= 0 \\
\frac{\partial L}{\partial \beta_{1}} &amp;= 0
\end{align*}
\]</span></p>
<p>However, there is an alternative approach that uses tools from linear algebra such as matrices and we will examine this approach for a few reasons:</p>
<ol type="1">
<li><p>It motivates the use of linear algebra and matrices in machine learning.</p></li>
<li><p>It helps provide a geometric perspective to machine learning.</p></li>
<li><p>It generalizes well to the situation when we have more than one predictor variable.</p></li>
</ol>
<p>The next section treats the linear algebra tools we will use for linear regression and the section after that applies linear algebra to do linear regression.</p>
<p><strong>Note:</strong> Linear regression can and often is used even in situations where we do not know <em>a priori</em> that <span class="math inline">\(f\)</span> in the relation <span class="math inline">\(y = f(x) + \epsilon\)</span> is linear.</p>
<p><strong>Question:</strong> What do you think some of the pros and cons of using linear regression for supervised learning even if the function <span class="math inline">\(f\)</span> in the relationship <span class="math inline">\(y = f(x) + \epsilon\)</span> might not be linear?</p>
</section>
<section id="overdetermined-linear-systems-and-qr-factorization" class="level2">
<h2 class="anchored" data-anchor-id="overdetermined-linear-systems-and-qr-factorization">Overdetermined Linear Systems and <span class="math inline">\(QR\)</span> Factorization</h2>
<p>Recall that a system of linear equations is an expression of the form</p>
<p><span class="math display">\[
\begin{align*}
a_{11}x_{1} + a_{12}x_{2} + \cdots + a_{1p} x_{p}  &amp;= b_{1} \\
a_{21}x_{1} + a_{22}x_{2} + \cdots + a_{2p} x_{p} &amp;= b_{2} \\
&amp;\vdots \\
a_{n1}x_{1} + a_{n2}x_{2} + \cdots + a_{np} x_{p} &amp;= b_{n}
\end{align*}
\]</span></p>
<p>where there are <span class="math inline">\(p\)</span> unknowns <span class="math inline">\(x_{j}\)</span>, <span class="math inline">\(n \times p\)</span> coefficients <span class="math inline">\(a_{ij}\)</span>, and <span class="math inline">\(n\)</span> given values <span class="math inline">\(b_{i}\)</span>. Such a system can be rewritten using matrix notation as</p>
<p><span class="math display">\[
\left[\begin{array}{cccc} a_{11} &amp; a_{12} &amp; \cdots &amp; a_{1p} \\ a_{21} &amp; a_{22} &amp; \cdots &amp; a_{2p} \\ \vdots &amp; \ddots &amp; \cdots &amp; \vdots \\ a_{n1} &amp; a_{n2} &amp; \cdots &amp; a_{np} \end{array}\right] \left[\begin{array}{c} x_{1} \\ x_{2} \\ \vdots \\ x_{p} \end{array} \right] = \left[\begin{array}{c} b_{1} \\ b_{2} \\ \vdots \\ b_{n} \end{array} \right]
\]</span></p>
<p>or even more concisely as</p>
<p><span class="math display">\[
A {\bf x} = {\bf b}
\]</span></p>
<p>and we say that <span class="math inline">\(A\)</span> is an <span class="math inline">\(n \times p\)</span> matrix.</p>
<p><strong>Definition:</strong> A linear system <span class="math inline">\(A {\bf x} = {\bf b}\)</span> is said to be <strong>overdetermined</strong> if there are more equations that unknowns. That is, if <span class="math inline">\(n &gt; p\)</span>.</p>
<p>We will soon see that the problem of linear regression typically corresponds to “solving” an overdetermined linear system. There’s a problem though, overdetermined linear systems do not usually have a solution. For example, consider the following linear system:</p>
<p><span class="math display">\[
\begin{align*}
x &amp;= 1 \\
x &amp;= 2
\end{align*}
\]</span> which is an overdetermined linear system since it has two equations in one unknown. This system clearly does not possess a solution.</p>
<p>Given an <span class="math inline">\(n \times p\)</span> matrix <span class="math inline">\(A\)</span> and an <span class="math inline">\(n\)</span>-vector <span class="math inline">\({\bf b}\)</span>, for any vector <span class="math inline">\(p\)</span>-vector <span class="math inline">\({\bf x}\)</span> we can always form the residual <span class="math inline">\({\bf r}\)</span> defined by</p>
<p><span class="math display">\[
{\bf r} = {\bf b} - A{\bf x}
\]</span> Note that <span class="math inline">\({\bf x}\)</span> is a solution to the linear system <span class="math inline">\(A{\bf x} = {\bf b}\)</span> is and only if the residual <span class="math inline">\({\bf r}\)</span> is the zero vector.</p>
<p>Now, based on the last example we cannot generally make the the residual zero for an overdetermined system. However, we could instead search for a vector <span class="math inline">\({\bf x}\)</span> that makes the residual as small as possible. In order to do so, we need a way to measure the size of a residual. Vector norms are a mathematical object that allow us to measure the size of residuals.</p>
<section id="norms-a-technical-tool" class="level3">
<h3 class="anchored" data-anchor-id="norms-a-technical-tool">Norms: A Technical Tool</h3>
<p><strong>Definition:</strong> A vector norm, denoted by <span class="math inline">\(\|\cdot \|\)</span> is an object that takes as input a vector and returns a real number while satisfying the following properties:</p>
<ol type="1">
<li><p>Positivity: For any vector <span class="math inline">\(\|{\bf v}\| \geq 0\)</span> and <span class="math inline">\(\|{\bf v}\| = 0\)</span> if and only if <span class="math inline">\({\bf v}\)</span> is the zero vector.</p></li>
<li><p>Homogeneity: If <span class="math inline">\(\alpha\)</span> is a number and <span class="math inline">\({\bf v}\)</span> is a vector, then <span class="math inline">\(\|\alpha {\bf v}\| = |\alpha| \|{\bf v}\|\)</span>.</p></li>
<li><p>Triangle inequality: For any vectors <span class="math inline">\({\bf u}\)</span> and <span class="math inline">\({\bf v}\)</span>, we have</p></li>
</ol>
<p><span class="math display">\[
\|{\bf u} + {\bf v} \| \leq \|{\bf u}\| + \|{\bf v}\|
\]</span> <strong>Example:</strong> The most relevant example for us, at least in the setting of linear regression is the 2-norm <span class="math inline">\(\|\cdot\|_{2}\)</span> which for a vector <span class="math inline">\({\bf v} = [\begin{array}{cccc} v_{1} &amp; v_{2} &amp; \cdots &amp; v_{n} \end{array}]^{T}\)</span> is defined by</p>
<p><span class="math display">\[
\|{\bf v}\|_{2} = \sqrt{v_{1}^2 + v_{2}^{2} + \cdots + v_{n}^{2}}
\]</span></p>
<p><strong>Defintion:</strong> Given a vector norm <span class="math inline">\(\|\cdot\|\)</span>, the <strong>distance between two vectors</strong> <span class="math inline">\({\bf u}\)</span> and <span class="math inline">\({\bf v}\)</span> is defined to be <span class="math inline">\(\|{\bf u} - {\bf v}\|\)</span>.</p>
<p><strong>Note:</strong> It is possible to generalize vector norms to norms on sets of functions. This is also useful in machine learning since this allows us to define a notion of distance between functions.</p>
</section>
<section id="linear-regression-and-linear-least-squares" class="level3">
<h3 class="anchored" data-anchor-id="linear-regression-and-linear-least-squares">Linear Regression and Linear Least Squares</h3>
<p>The 2-norm allows us to define the <strong>linear least squares problem:</strong></p>
<blockquote class="blockquote">
<p>Given an <span class="math inline">\(n \times p\)</span> matrix <span class="math inline">\(A\)</span> and a <span class="math inline">\(n\)</span>-vector <span class="math inline">\({\bf b}\)</span>, find a vector <span class="math inline">\({\bf x}\)</span> that satifies</p>
</blockquote>
<p><span class="math display">\[
\|{\bf b} - A{\bf x}\|_{2} \leq \|{\bf b} - A{\bf \xi}\|_{2} , \ \ \text{for all vectors } {\bf \xi}
\]</span> That is, the linear least squares problem is to find a vector that minimizes the corresponding residual with respect to the 2-norm.</p>
<p><strong>Example:</strong> Consider again the linear system</p>
<p><span class="math display">\[
\begin{align*}
x &amp;= 1 \\
x &amp;= 2
\end{align*}
\]</span></p>
<p>Then the linear least squares problem in this case is to find the value <span class="math inline">\(x\)</span> such that</p>
<p><span class="math display">\[
\sqrt{(x-1)^2 + (x-2)^2}
\]</span></p>
<p>is as small as possible. Note that this is equivalent to minimizing</p>
<p><span class="math display">\[
(x-1)^2 + (x-2)^2 = 2x^2 - 6x + 5
\]</span></p>
<p>In general, minimizing the residual in the 2-norm corresponds to minimizing a multi-variable quadratic function. However, we can use linear algebra instead of calculus to solve the linear least squares problem. The main tool we need is what is known as the <span class="math inline">\(QR\)</span> factorization or decomposition of a matrix.</p>
</section>
<section id="qr-factorization" class="level3">
<h3 class="anchored" data-anchor-id="qr-factorization"><span class="math inline">\(QR\)</span> Factorization</h3>
<p>Consider the following example that can easily be checked by hand.</p>
<p><span class="math display">\[
\left[\begin{array}{cc} 3 &amp; 1 \\ 4 &amp; 2 \end{array}\right] = \left[\begin{array}{cc} \frac{3}{5} &amp; -\frac{4}{5} \\ \frac{4}{5} &amp; \frac{3}{5} \end{array}\right]\left[\begin{array}{cc} 5 &amp; \frac{11}{5} \\ 0 &amp; \frac{2}{5} \end{array}\right]
\]</span></p>
<p>This has the form <span class="math inline">\(A = QR\)</span> and what is really interesting here is that</p>
<ol type="1">
<li><p>The matrix <span class="math inline">\(Q = \left[\begin{array}{cc} \frac{3}{5} &amp; -\frac{4}{5} \\ \frac{4}{5} &amp; \frac{3}{5} \end{array}\right]\)</span> satisfies that <span class="math inline">\(QQ^{T} = I\)</span> and <span class="math inline">\(Q^{T}Q = I\)</span>. We refer to any matrix that satisfies such properties as an <strong>orthogonal</strong> matrix.</p></li>
<li><p>The matrix <span class="math inline">\(R = \left[\begin{array}{cc} 5 &amp; \frac{11}{5} \\ 0 &amp; \frac{2}{5} \end{array}\right]\)</span> is <strong>upper triangular</strong> since all the entries below the main diagonal are zero.</p></li>
</ol>
<p>Every matrix has a <span class="math inline">\(QR\)</span> factorization and it is unique if <span class="math inline">\(n \geq p\)</span> and <span class="math inline">\(A\)</span> is of full rank. Further, the <span class="math inline">\(QR\)</span> factorization can be used to solve the linear least squares problem as follows:</p>
<ol type="1">
<li><p>Compute <span class="math inline">\(A = QR\)</span>, the <span class="math inline">\(QR\)</span> factorization <a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a>. There are efficient algorithms for doing this.</p></li>
<li><p>Form the vector <span class="math inline">\(Q^{T}{\bf b}\)</span>.</p></li>
<li><p>Solve the linear system <span class="math inline">\(R{\bf x} = Q^{T}{\bf b}\)</span>.</p></li>
</ol>
<p>The system in point 3 is relatively easy to solve. Since <span class="math inline">\(R\)</span> is upper triangular, the system <span class="math inline">\(R{\bf x} = Q^{T}{\bf b}\)</span> can be solved by a simple algorithm known as backward substitution which is implemented in R by the function <code>backsolve</code>.</p>
<section id="computing-the-qr-factorization-with-r" class="level4">
<h4 class="anchored" data-anchor-id="computing-the-qr-factorization-with-r">Computing the <span class="math inline">\(QR\)</span> Factorization with R</h4>
<p>The following R code shows how the create a matrix, compute its <span class="math inline">\(QR\)</span> factorization with the function <code>qr</code>, and then extract the matrices <span class="math inline">\(Q\)</span> and <span class="math inline">\(R\)</span>:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a>A <span class="ot">&lt;-</span> <span class="fu">matrix</span>(<span class="fu">c</span>(<span class="dv">3</span>,<span class="dv">1</span>,<span class="dv">4</span>,<span class="dv">2</span>),<span class="dv">2</span>,<span class="dv">2</span>,<span class="at">byrow =</span> <span class="cn">TRUE</span>)</span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a>A_qr <span class="ot">&lt;-</span> <span class="fu">qr</span>(A)</span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a>Q <span class="ot">&lt;-</span> <span class="fu">qr.Q</span>(A_qr)</span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a>R <span class="ot">&lt;-</span> <span class="fu">qr.R</span>(A_qr)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Let’s check that <span class="math inline">\(QR = A\)</span>:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a>Q <span class="sc">%*%</span> R</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>     [,1] [,2]
[1,]    3    1
[2,]    4    2</code></pre>
</div>
</div>
<p>Let’s check that <span class="math inline">\(Q\)</span> is an orthogonal matrix:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="fu">round</span>(Q <span class="sc">%*%</span> <span class="fu">t</span>(Q),<span class="dv">2</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>     [,1] [,2]
[1,]    1    0
[2,]    0    1</code></pre>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="fu">round</span>(<span class="fu">t</span>(Q) <span class="sc">%*%</span> Q,<span class="dv">2</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>     [,1] [,2]
[1,]    1    0
[2,]    0    1</code></pre>
</div>
</div>
</section>
</section>
</section>
<section id="simple-linear-regression" class="level2">
<h2 class="anchored" data-anchor-id="simple-linear-regression">Simple Linear Regression</h2>
<p>Return to the data shown in <a href="#fig-slr">Figure&nbsp;1</a> and <a href="#fig-a-resid">Figure&nbsp;2</a>. Fitting a line to this data means finding values for the intercept <span class="math inline">\(\hat{\beta}_{0}\)</span> and slope <span class="math inline">\(\hat{\beta}_{1}\)</span> so that for each data point <span class="math inline">\((x_{i},y_{i})\)</span> we have that</p>
<p><span class="math display">\[
\hat{\beta}_{0} + \hat{\beta}_{1} x_{i} = \hat{\beta}_{0} \cdot 1 + \hat{\beta}_{1} x_{i}
\]</span></p>
<p>is as close as possible to <span class="math inline">\(y_{i}\)</span>. We can rewrite the last expression as a matrix vector product:</p>
<p><span class="math display">\[
X {\bf \beta} =  \left[\begin{array}{cc} 1 &amp; x_{1} \\ 1 &amp; x_{2} \\ \vdots &amp; \vdots \\ 1 &amp; x_{n} \end{array}\right]\left[\begin{array}{c} \beta_{0} \\ \beta_{1} \end{array}\right]
\]</span></p>
<p>In order to account for the intercept coefficient, we have to add the column of ones. We call the matrix <span class="math inline">\(X\)</span> so formed the <strong>data matrix</strong> and the vector <span class="math inline">\({\bf \beta}\)</span> the parameter vector. Thus, we can write the linear regression problem as a linear least squares problem to minimize the residual <span class="math inline">\({\bf r} = {\bf y} - X{\bf \beta}\)</span>. Minimizing this is the 2-norm is the same as minimizing the squared error. Let’s see this worked out in a computational example.</p>
<section id="an-example" class="level3">
<h3 class="anchored" data-anchor-id="an-example">An Example</h3>
<p>The following R code constructs the data matrix <span class="math inline">\(X\)</span>, computes the <span class="math inline">\(QR\)</span> factorization for <span class="math inline">\(X\)</span>, and then applies the backward substitution algorithm to solve <span class="math inline">\(R{\bf \beta} = Q^{T}{\bf y}\)</span>:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb11"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a>y_vect <span class="ot">&lt;-</span> xy_data <span class="sc">%&gt;%</span> <span class="fu">pull</span>(y)</span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a>y_vect <span class="ot">&lt;-</span> <span class="fu">matrix</span>(y_vect,<span class="at">ncol =</span> <span class="dv">1</span>)</span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a>X_mat <span class="ot">&lt;-</span> xy_data <span class="sc">%&gt;%</span> </span>
<span id="cb11-4"><a href="#cb11-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">int_ones =</span> <span class="fu">rep</span>(<span class="dv">1</span>,<span class="fu">nrow</span>(xy_data))) <span class="sc">%&gt;%</span> </span>
<span id="cb11-5"><a href="#cb11-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">select</span>(int_ones,x) <span class="sc">%&gt;%</span> </span>
<span id="cb11-6"><a href="#cb11-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">as.matrix</span>()</span>
<span id="cb11-7"><a href="#cb11-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-8"><a href="#cb11-8" aria-hidden="true" tabindex="-1"></a>X_qr <span class="ot">&lt;-</span> <span class="fu">qr</span>(X_mat)</span>
<span id="cb11-9"><a href="#cb11-9" aria-hidden="true" tabindex="-1"></a>R_mat <span class="ot">&lt;-</span> <span class="fu">qr.R</span>(X_qr) </span>
<span id="cb11-10"><a href="#cb11-10" aria-hidden="true" tabindex="-1"></a>Q_mat <span class="ot">&lt;-</span> <span class="fu">qr.Q</span>(X_qr)</span>
<span id="cb11-11"><a href="#cb11-11" aria-hidden="true" tabindex="-1"></a>(beta_vals <span class="ot">&lt;-</span> <span class="fu">backsolve</span>(R_mat,<span class="fu">t</span>(Q_mat) <span class="sc">%*%</span> y_vect))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>         [,1]
[1,] 1.774549
[2,] 0.742658</code></pre>
</div>
</div>
<p>Now that we have estimated model coefficients, we can use that information to make predictions with the model. For example,</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb13"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a>beta_vals_vect <span class="ot">&lt;-</span> <span class="fu">matrix</span>(beta_vals,<span class="at">ncol=</span><span class="dv">1</span>,<span class="at">byrow =</span> <span class="cn">TRUE</span>)</span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a>X_new <span class="ot">&lt;-</span> <span class="fu">matrix</span>(<span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">67</span>),<span class="dv">1</span>,<span class="dv">2</span>,<span class="at">byrow=</span><span class="cn">TRUE</span>)</span>
<span id="cb13-3"><a href="#cb13-3" aria-hidden="true" tabindex="-1"></a>(y_pred <span class="ot">&lt;-</span> X_new <span class="sc">%*%</span> beta_vals_vect)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>         [,1]
[1,] 51.53264</code></pre>
</div>
</div>
</section>
<section id="fitting-linear-models-with-r" class="level3">
<h3 class="anchored" data-anchor-id="fitting-linear-models-with-r">Fitting Linear Models with R</h3>
<p>There are many functions in base R and other packages that can be used to fit not only linear models but a variety of many different types of models. In base R, we have a function <code>lm</code> that can be used to fit a linear regression model. Let’s examine the documentation for <code>lm</code>. We see that the first argument for <code>lm</code> is a formula. Many modeling functions in base R and other packages accept utilize a formula to represent the model specification. The easiest way to understand this is to see some examples.</p>
<p>Let’s compare what R does when we use the function <code>lm</code> to fit a linear model with our earlier approach of using <span class="math inline">\(QR\)</span> factorization.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb15"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a>lm_fit <span class="ot">&lt;-</span> <span class="fu">lm</span>(y <span class="sc">~</span> x,<span class="at">data=</span>xy_data)</span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-3"><a href="#cb15-3" aria-hidden="true" tabindex="-1"></a><span class="fu">coefficients</span>(lm_fit)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>(Intercept)           x 
   1.774549    0.742658 </code></pre>
</div>
</div>
<p>Under the hood, the <code>lm</code> function in R is using the <span class="math inline">\(QR\)</span> factorization to compute the slope and intercept for the line in figures like <a href="#fig-a-resid">Figure&nbsp;2</a> and <a href="#fig-resids">Figure&nbsp;3</a>.</p>
<p>We can also make predictions on new data with <code>lm</code> models:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb17"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a><span class="fu">predict</span>(lm_fit,<span class="at">newdata=</span><span class="fu">tibble</span>(<span class="at">x=</span><span class="dv">67</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>       1 
51.53264 </code></pre>
</div>
</div>
</section>
</section>
<section id="multiple-linear-regression" class="level2">
<h2 class="anchored" data-anchor-id="multiple-linear-regression">Multiple Linear Regression</h2>
<p>Suppose that we have data of the form <span class="math inline">\((y_{i},{\bf x}_{i}) = (y_{i},x_{i1},x_{i2},\ldots , x_{ip})\)</span> so that there are <span class="math inline">\(p\)</span> predictor variables. The multiple linear regression model takes the form</p>
<p><span class="math display">\[
y = \beta_{0} + \beta_{1}{\bf x}_{1} + \beta_{2}{\bf x}_{2} + \cdots + \beta_{p}{\bf x}_{p} + \epsilon
\]</span></p>
<p>Taking into account the column of ones we can form a <span class="math inline">\(n \times (p + 1)\)</span> sized data matrix and again use <span class="math inline">\(QR\)</span> factorization to solve the corresponding linear least squares problem for the residual <span class="math inline">\({\bf r} = {\bf y} - X{\bf \beta}\)</span>. Now, our coefficient vector <span class="math inline">\({\bf \beta}\)</span> will have length <span class="math inline">\(p+1\)</span>.</p>
<p>Multiple linear regression is a significant generalization of simple linear regression because it not only allows us to account for multiple predictor variables, but also allows us to account for certain types of nonlinearity and also predictor variables that are categorical. This is because:</p>
<ol type="1">
<li><p>The “linear” part of linear regression refers to linearity with respect to the coefficients <span class="math inline">\({\bf \beta}\)</span>.</p></li>
<li><p>We can use dummy variables to represent categorical predictor variables.</p></li>
</ol>
<p>The point is, as long as our data can be represented by a data matrix <span class="math inline">\(X\)</span>, then we can try to use <span class="math inline">\(QR\)</span> factorization to solve the linear least squares problem to minimize the residuals <span class="math inline">\({\bf r} = {\bf y} - X{\bf \beta}\)</span>.</p>
<p>We can use the <code>lm</code> function to easily fit multiple linear regression models. Let’s work through some examples together.</p>
</section>
<section id="linear-regression-in-machine-learning" class="level2">
<h2 class="anchored" data-anchor-id="linear-regression-in-machine-learning">Linear Regression in Machine Learning</h2>
<p>Through our study of linear regression, we have derived and implemented our first supervised machine learning algorithm. We have also seen in our worked examples how to use <code>tidymodels</code> to apply linear regression as a machine learning algorithm. In particular, we have seen how to:</p>
<ul>
<li><p>Account for certain types of nonlinearity.</p></li>
<li><p>Account for categorical predictors.</p></li>
<li><p>Separate data into a training set and a test set.</p></li>
<li><p>Set up and fit a model.</p></li>
<li><p>Use a model to make predictions.</p></li>
<li><p>Assess model accuracy by computing the root mean square error.</p></li>
</ul>
<p>However, there are several additional considerations we still need to address. For example,</p>
<ul>
<li><p>Assessing model uncertainty.</p></li>
<li><p>Choosing which predictors to include or not in a model.</p></li>
<li><p>Deciding between different classes of models.</p></li>
</ul>
<p>We will take up these issues soon but before doing so, we will first look at a learning algorithm for a classification problem.</p>
</section>
<section id="preparation-for-the-next-lesson" class="level2">
<h2 class="anchored" data-anchor-id="preparation-for-the-next-lesson">Preparation for the next lesson</h2>
<p>For the next lesson:</p>
<ul>
<li><p>Read chapter 4 from of <em>An Introduction to Statistical Learning</em> <span class="citation" data-cites="tibshirani2017introduction">(<a href="#ref-tibshirani2017introduction" role="doc-biblioref">Tibshirani, James, and Trevor 2017</a>)</span>. You may also want to read chapter 3 of <em>Statistical Learning with Math and R</em> <span class="citation" data-cites="suzuki2020statistical">(<a href="#ref-suzuki2020statistical" role="doc-biblioref">Suzuki 2020</a>)</span>.</p></li>
<li><p>Watch the corresponding video lecture on classification. <a href="https://youtu.be/BMJQ3LQ_QKU?si=XvFgGO2jJ5OyR-v4">View on YouTube</a>.</p></li>
</ul>
<div class="cell">
<div class="cell-output-display">
<div class="vembedr" align="center">
<div>
<iframe src="https://www.youtube.com/embed/BMJQ3LQ_QKU?si=XvFgGO2jJ5OyR-v4" width="800" height="450" frameborder="0" allowfullscreen="" data-external="1"></iframe>
</div>
</div>
</div>
</div>
</section>
<section id="references" class="level2">
<h2 class="anchored" data-anchor-id="references">References</h2>
<div id="refs" class="references csl-bib-body hanging-indent" role="list">
<div id="ref-suzuki2020statistical" class="csl-entry" role="listitem">
Suzuki, Joe. 2020. <em>Statistical Learning with Math and r</em>. Springer.
</div>
<div id="ref-tibshirani2017introduction" class="csl-entry" role="listitem">
Tibshirani, Hastie Robert, Gareth James, and Daniela Witten Trevor. 2017. <em>An Introduction to Statistical Learning</em>. springer publication.
</div>
</div>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-1-contents" aria-controls="callout-1" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Expand for Session Info
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-1" class="callout-1-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<div class="cell">
<div class="cell-output cell-output-stdout">
<pre><code>─ Session info ───────────────────────────────────────────────────────────────
 setting  value
 version  R version 4.3.1 (2023-06-16)
 os       macOS Sonoma 14.0
 system   aarch64, darwin20
 ui       X11
 language (EN)
 collate  en_US.UTF-8
 ctype    en_US.UTF-8
 tz       America/New_York
 date     2023-10-16
 pandoc   3.1.8 @ /opt/homebrew/bin/ (via rmarkdown)
 quarto   1.3.450 @ /usr/local/bin/quarto

─ Packages ───────────────────────────────────────────────────────────────────
 package      * version date (UTC) lib source
 broom        * 1.0.5   2023-06-09 [1] CRAN (R 4.3.0)
 dplyr        * 1.1.3   2023-09-03 [1] CRAN (R 4.3.0)
 forcats      * 1.0.0   2023-01-29 [1] CRAN (R 4.3.0)
 ggplot2      * 3.4.4   2023-10-12 [1] CRAN (R 4.3.1)
 ISLR2        * 1.3-2   2022-11-20 [1] CRAN (R 4.3.0)
 lubridate    * 1.9.3   2023-09-27 [1] CRAN (R 4.3.1)
 purrr        * 1.0.2   2023-08-10 [1] CRAN (R 4.3.0)
 readr        * 2.1.4   2023-02-10 [1] CRAN (R 4.3.0)
 sessioninfo  * 1.2.2   2021-12-06 [1] CRAN (R 4.3.0)
 stringr      * 1.5.0   2022-12-02 [1] CRAN (R 4.3.0)
 tibble       * 3.2.1   2023-03-20 [1] CRAN (R 4.3.0)
 tidyr        * 1.3.0   2023-01-24 [1] CRAN (R 4.3.0)
 tidytuesdayR * 1.0.2   2022-02-01 [1] CRAN (R 4.3.0)
 tidyverse    * 2.0.0   2023-02-22 [1] CRAN (R 4.3.0)

 [1] /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/library

──────────────────────────────────────────────────────────────────────────────</code></pre>
</div>
</div>
</div>
</div>
</div>
<div class="quarto-figure quarto-figure-left">
<figure class="figure">
<p><a href="https://creativecommons.org/licenses/by-nc-sa/4.0/legalcode"><img src="http://mirrors.creativecommons.org/presskit/buttons/88x31/png/by-nc-sa.png?raw=1" class="img-fluid figure-img" style="width:15.0%"></a></p>
</figure>
</div>


</section>


<div id="quarto-appendix" class="default"><section id="footnotes" class="footnotes footnotes-end-of-document" role="doc-endnotes"><h2 class="anchored quarto-appendix-heading">Footnotes</h2>

<ol>
<li id="fn1"><p>Technically we are assuming that <span class="math inline">\(A = QR\)</span> is the <em>reduced</em> <span class="math inline">\(QR\)</span> factorization meaning that <span class="math inline">\(R\)</span> has size <span class="math inline">\(p \times p\)</span>.<a href="#fnref1" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
</ol>
</section><section class="quarto-appendix-contents"><h2 class="anchored quarto-appendix-heading">Reuse</h2><div id="quarto-reuse" class="quarto-appendix-contents"><div>CC BY-NC-SA 4.0</div></div></section></div></main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const disableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'prefetch';
    }
  }
  const enableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'stylesheet';
    }
  }
  const manageTransitions = (selector, allowTransitions) => {
    const els = window.document.querySelectorAll(selector);
    for (let i=0; i < els.length; i++) {
      const el = els[i];
      if (allowTransitions) {
        el.classList.remove('notransition');
      } else {
        el.classList.add('notransition');
      }
    }
  }
  const toggleColorMode = (alternate) => {
    // Switch the stylesheets
    const alternateStylesheets = window.document.querySelectorAll('link.quarto-color-scheme.quarto-color-alternate');
    manageTransitions('#quarto-margin-sidebar .nav-link', false);
    if (alternate) {
      enableStylesheet(alternateStylesheets);
      for (const sheetNode of alternateStylesheets) {
        if (sheetNode.id === "quarto-bootstrap") {
          toggleBodyColorMode(sheetNode);
        }
      }
    } else {
      disableStylesheet(alternateStylesheets);
      toggleBodyColorPrimary();
    }
    manageTransitions('#quarto-margin-sidebar .nav-link', true);
    // Switch the toggles
    const toggles = window.document.querySelectorAll('.quarto-color-scheme-toggle');
    for (let i=0; i < toggles.length; i++) {
      const toggle = toggles[i];
      if (toggle) {
        if (alternate) {
          toggle.classList.add("alternate");     
        } else {
          toggle.classList.remove("alternate");
        }
      }
    }
    // Hack to workaround the fact that safari doesn't
    // properly recolor the scrollbar when toggling (#1455)
    if (navigator.userAgent.indexOf('Safari') > 0 && navigator.userAgent.indexOf('Chrome') == -1) {
      manageTransitions("body", false);
      window.scrollTo(0, 1);
      setTimeout(() => {
        window.scrollTo(0, 0);
        manageTransitions("body", true);
      }, 40);  
    }
  }
  const isFileUrl = () => { 
    return window.location.protocol === 'file:';
  }
  const hasAlternateSentinel = () => {  
    let styleSentinel = getColorSchemeSentinel();
    if (styleSentinel !== null) {
      return styleSentinel === "alternate";
    } else {
      return false;
    }
  }
  const setStyleSentinel = (alternate) => {
    const value = alternate ? "alternate" : "default";
    if (!isFileUrl()) {
      window.localStorage.setItem("quarto-color-scheme", value);
    } else {
      localAlternateSentinel = value;
    }
  }
  const getColorSchemeSentinel = () => {
    if (!isFileUrl()) {
      const storageValue = window.localStorage.getItem("quarto-color-scheme");
      return storageValue != null ? storageValue : localAlternateSentinel;
    } else {
      return localAlternateSentinel;
    }
  }
  let localAlternateSentinel = 'default';
  // Dark / light mode switch
  window.quartoToggleColorScheme = () => {
    // Read the current dark / light value 
    let toAlternate = !hasAlternateSentinel();
    toggleColorMode(toAlternate);
    setStyleSentinel(toAlternate);
  };
  // Ensure there is a toggle, if there isn't float one in the top right
  if (window.document.querySelector('.quarto-color-scheme-toggle') === null) {
    const a = window.document.createElement('a');
    a.classList.add('top-right');
    a.classList.add('quarto-color-scheme-toggle');
    a.href = "";
    a.onclick = function() { try { window.quartoToggleColorScheme(); } catch {} return false; };
    const i = window.document.createElement("i");
    i.classList.add('bi');
    a.appendChild(i);
    window.document.body.appendChild(a);
  }
  // Switch to dark mode if need be
  if (hasAlternateSentinel()) {
    toggleColorMode(true);
  } else {
    toggleColorMode(false);
  }
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->



</body></html>