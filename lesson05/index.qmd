---
title: "Lesson 5"
subtitle: "Resampling"
author: "JMG"
format:
  html:
    code-fold: true
    code-summary: "Show the code"
    toc: true
    toc-location: left
bibliography: lesson05.bib
license: "CC BY-NC-SA 4.0"
---

```{r}
#| message: false
#| warning: false
#| echo: false

# load packages used in document
library(tidyverse)
library(tidymodels)
library(broom)
library(kableExtra)

tidymodels_prefer()

theme_set(theme_minimal(base_size = 13))
```

## Learning Objectives

After this lesson, students will be able to:

* Define the bootstrap method.

* Define cross-validation and distinguish between different approaches to cross-validation. 

* Use the methods in the `rsample` package to generate appropriate resamples.

* Apply bootstrap and cross-validation methods to obtain relevant information about regression and classification models. 

## Readings, etc.

For this lesson:

- Read chapter 5 from of *An Introduction to Statistical Learning* [@tibshirani2017introduction]. You may also want to read chapter 4 of *Statistical Learning with Math and R* [@suzuki2020statistical].

-   Watch the corresponding video lecture on cross validation. [View on YouTube](https://youtu.be/6eWODQJrMKs?si=tPPLUz9g9TMCt6EL).

```{r}
#| echo: false

vembedr::embed_youtube(id="6eWODQJrMKs?si=tPPLUz9g9TMCt6EL",height=450) %>%
  vembedr::use_align("center")
```

-   Watch the "Spending your data budget" section of the following video. [View on YouTube](https://youtu.be/sv5r7CVAVwo?si=NHpjUOHurbYfEm0L).

```{r}
#| echo: false

vembedr::embed_youtube(id="sv5r7CVAVwo?si=NHpjUOHurbYfEm0L",height=450) %>%
  vembedr::use_start_time("31m29s") %>%
  vembedr::use_align("center")
```


## Overview

Machine learning algorithms estimate parameters or other features of a model. It is important to assess the accuracy or uncertainty associated with any estimate. For the purposes of prediction, we are ultimately concerned with how a model performs on a previously unseen set of test data. However, as soon as the model sees the test data, it should not be used again. Thus, in choosing a good model we need to be able to estimate test error without directly use of the test set. Furthermore, we have seen that the specification of some types of models requires the selection of values for one or more hyperparameters.    

Notice that in both cases of model fitting and model assessment, there is something that we want to estimate and the value of the estimate will depend on the sampled data. For example, in model fitting we may estimate a parameter while in model assessment we will estimate the test error. From a statistical perspective, we can view whatever it is we are estimating as a random variable so that our problem becomes to learn as much as we can about the distribution of that random variable.  

[Resampling methods](https://en.wikipedia.org/wiki/Resampling_(statistics)) involve judiciously choosing multiple subsets of our data, typically the training set as a way to solve the problems outlined in the last paragraph. The [bootstrap](https://en.wikipedia.org/wiki/Bootstrapping_(statistics)) samples with replacement from the data in order to assess the accuracy or uncertainty associated with an estimate. [Cross-validation](https://en.wikipedia.org/wiki/Cross-validation_(statistics)) (CV) holds out pieces of the data in order to assess the predictive accuracy of a model or to select hyperparameter values. 

Resampling methods are computation intensive because they involve refitting or re-estimating a model or parameters many times. On the other hand, resampling methods can be used in many more situations than analytic procedures can. Further, with the increased power and speed of modern computers and efficient implementations of algorithms used for resampling, resampling methods have become indispensable tools in modern statistics and machine learning. 

The R package [`rsample`](https://rsample.tidymodels.org/), which is part of the `tidymodels` family provides functions to create different types of resamples and facilitates their use in many analyses. The `rsample` package provides a set of methods that can be used for:

* Resampling for estimating the sampling distribution of a statistic.

* Estimating model performance using a holdout set.

In this lesson, we will explain in detail the bootstrap and cross-validation resampling methods and learn how to use `rsample` for generating resamples. We will also see some use cases for the bootstrap and cross-validation.

## Bootstrap

A common assumption of statistical models is that we have an independent and identically distributed sequence of random variables. Mathematically, $X_{1}, X_{2}, \ldots , X_{n} \sim F$, where $F$ is a (typically unknown) cumulative distribution function. The **empirical distribution function** (EDF) $\hat{F}_{n}$ is defined by

$$
\hat{F}_{n}(x) = \frac{1}{n}\sum_{i=1}^{n}I(X_{i} \leq x)
$$

where $I$ is the indicator function we have seen before. The EDF satisfies for any fixed value $x$:

1. $\text{E}[\hat{F}_{n}(x)] = F(x)$, and

2. $\text{Var}[\hat{F}_{n}(x)] = \frac{F(x)(1 - F(x))}{n}$

For a statistic, that is, any function of the sample $T_{n} = g(X_{1},X_{2},\ldots, X_{n})$ the bootstrap estimates the variance $\text{Var}_{F}(T_{n})$ by $\text{Var}_{\hat{F}_{n}}(T_{n})$. This is what's called a **plug-in** estimator. Here's how it works in practice:

1. Draw a sample $X_{1}^{\ast}, \ldots , X_{n}^{\ast} \sim \hat{F}_{n}$.

2. Compute $T_{n}^{\ast} = g(X_{1}^{\ast}, \ldots , X_{n}^{\ast})$.

3. Repeat steps 1 and 2, $B$ times to get $T_{n,1}^{\ast}, \ldots T_{n,B}^{\ast}$.

4. Define the **bootstrap variance** by

$$
\mathcal{v}_{\text{boot}} = \frac{1}{B}\sum_{b=1}^{B}\left(T_{n,b}^{\ast} - \frac{1}{B}\sum_{r=1}^{B}T_{n,r}^{\ast} \right)^{2}
$$
It can be shown that $\mathcal{v}_{\text{boot}}$ converges in a specific sense to $\text{Var}_{\hat{F}_{n}}(T_{n})$ as $B \rightarrow \infty$. To do this, we need to simulate $\hat{F}_{n}$. Since $\hat{F}_{n}$ give probability $\frac{1}{n}$ to each data point, drawing $n$ points at random from $\hat{F}_{n}$ is the same as drawing a sample of size $n$ **with replacement** from the original data. So, we would replace step 1 above with

1'. Draw $X_{1}^{\ast}, \ldots , X_{n}^{\ast}$ with replacement from $X_{1}, \ldots , X_{n}$.

Intuitively, if a sample is representative of a population, then many samples with replacement from the sample should be representative of the sampling distribution. @fig-bootstrap-illustration illustrates the bootstrap resampling process. 

![An illustration of the bootstrap idea.](https://upload.wikimedia.org/wikipedia/commons/thumb/4/4a/Illustration_bootstrap.svg/1920px-Illustration_bootstrap.svg.png){#fig-bootstrap-illustration height=4in width=10in}

Let's look at a simple example by bootstraping the median of some sample data:

```{r}
#| code-fold: false
set.seed(1234)
sample_data <- rnorm(45,mean = 5, sd = 2.75)

(t_med <- median(sample_data))

med_resamp <- function(id_val){
 ts_med <- median(sample(sample_data,replace=TRUE)) 
}

B <- 1000

ts_med_vals <- map_dbl(1:B,med_resamp)

(se_boot <- sd(ts_med_vals))
```


We can plot our bootstrapped median estimates to get an even better understanding of the variation of our statistic:

```{r}
#| label: fig-bootstrap-meds
#| fig-cap: The distribution of our boootstrapped median estimates.
ts_meds_df <- tibble(ts_meds = ts_med_vals)

ts_meds_df %>%
  ggplot(aes(x=ts_meds)) + 
  geom_histogram(color="white",fill="darkgrey",bins=25) + 
  labs(x = "Bootstrap median")
```

In @fig-bootstrap-meds we see that the mean of our bootstrap estimates is the value of the statistic for the original sample data. 

## Cross-validation




![](https://miro.medium.com/v2/resize:fit:640/format:webp/1*PdwlCactbJf8F8C7sP-3gw.png){#fig-cv-illustration height=4in width=8in}


## `r icons::icon_style(icons::fontawesome("r-project"),scale=2,fill="steelblue")` Using `rsample`

The `rsample` package contains functions to create various types of "data splits" and can be used for purposes of resampling. Some examples of functions from `rsample` include:

- `initial_split` - creates a single binary split of the data into a training set and testing set. We have seen this function before, it creates a so-called `rsplit` object. 

```{r}
#| code-fold: false


initial_split(penguins)
```

- `initial_validation_split` - creates a random three-way split of the data into a training set, a validation set, and a testing set. This can be used for very simple tuning tasks or in case you have a very large data set. It creates a `rsplot` object similar to `initial_split`. 

```{r}
#| code-fold: false


initial_validation_split(penguins)
```

- `bootstraps` -  creates samples that are the same size as the original data set that is made using replacement. This creates a data frame with a column of `rsplit` objects named `splits`.

```{r}
#| code-fold: false


bootstraps(penguins,times=5)
```

- `vfold_cv` - randomly splits the data into V groups of roughly equal size (called "folds"). Also creates a data frame with a column of `rsplit` objects named `splits`.


```{r}
#| code-fold: false


vfold_cv(penguins,v=5)
```

**Note:** There are a couple of other similar functions such as `loo_cv` and `mc_cv` that you will be asked to explore in the homework. 

Note that resampled data sets created by `rsample` are directly accessible in a resampling object but do not contain much overhead in memory. Since the original data is not modified, R does not make an automatic copy. For example, creating 50 bootstraps of a data set does not create an object that is 50-fold larger in memory.

@tbl-rsample-examp shows the results of a workflow involving `rsample` created with the following code: 

```{r}
#| label: tbl-rsample-examp
#| tbl-cap: Out put from an example workflow for `rsample`.


bootstraps(penguins,times=5) %>%
  mutate(analysis_df = map(splits, ~analysis(.x)),
         assessment_df = map(splits, ~assessment(.x))) %>%
  unnest(analysis_df) %>%
  group_by(id) %>%
  summarise(boot_mean_bill_length_mm = mean(bill_length_mm ,na.rm=TRUE),
            boot_median_bill_length_mm = median(bill_length_mm ,na.rm=TRUE),
            boot_sd_bill_length_mm = sd(bill_length_mm ,na.rm=TRUE)) %>%
  kable()
```

Essentially what the code has done is to create 5 bootstrap samples from a data set, extract the data frame of each bootstrap resample, and then compute some statistics for a variable in the data frame of each bootstrap resample. Let's experiment with this code in our own R session and work together on some further examples of using `rsample`. 



## Preparation for the next lesson



For the next lesson we will cover tree-based methods. To prepare for the next lesson, please do the following:

-   Read chapter 8 from of *An Introduction to Statistical Learning* [@tibshirani2017introduction]. You may also want to read chapter 8 of *Statistical Learning with Math and R* [@suzuki2020statistical].

-   Watch the corresponding video lecture on decision trees. [View on YouTube](https://youtu.be/QNnayf--_yk?si=x-oVRRqQE1cK-oZJ).

```{r}
#| echo: false

vembedr::embed_youtube(id="QNnayf--_yk?si=x-oVRRqQE1cK-oZJ",height=450) %>%
  vembedr::use_align("center")
```


- Go through the following two blog posts by Julia Silge:

    - [Predicting injuries for Chicago traffic crashes](https://juliasilge.com/blog/chicago-traffic-model/)
    
    - [Predict availability in water sources with random forest models](https://juliasilge.com/blog/water-sources/)



## References

::: {#refs}
:::

::: {.callout-tip collapse="true"}
## Expand for Session Info

```{r}
#| echo: false


library(sessioninfo)
# save the session info as an object
pkg_sesh <- session_info(pkgs = "attached")

# get the quarto version
quarto_version <- system("quarto --version", intern = TRUE)

# inject the quarto info
pkg_sesh$platform$quarto <- paste(
  system("quarto --version", intern = TRUE), 
  "@", 
  quarto::quarto_path()
  )

# print it out
pkg_sesh
```
:::

[![](http://mirrors.creativecommons.org/presskit/buttons/88x31/png/by-nc-sa.png?raw=1){fig-align="left" width="15%"}](https://creativecommons.org/licenses/by-nc-sa/4.0/legalcode)




