---
title: "Lesson 2"
subtitle: "Fundamental Machine Learning Concepts"
author: "JMG"
format:
  html:
    code-fold: true
    code-summary: "Show the code"
    toc: true
    toc-location: left
bibliography: lesson02.bib
license: "CC BY-NC-SA 4.0"
---

```{r}
#| message: false
#| warning: false
#| echo: false

# load packages used in document
library(tidyverse)
library(tidytuesdayR)
library(ISLR2)

theme_set(theme_minimal(base_size = 13))
```

## Learning Objectives

After this lesson, students will be able to:

* Define machine learning in general terms and distinguish between supervised and unsupervised learning problems. 

* Distinguish between regression and classification problems.

* Understand the concept of error and the significance of test versus training error. 

* Appreciate the trade-off between model flexibility and interpretability, and between bias and variance. 


## Readings, etc.

1) Read Chapter 2 of *An Introduction to Statistical Learning* [@tibshirani2017introduction]. 

2) The following two video lectures are also recommended:

* Motivating problems for machine (statistical) learning. [Watch video on YouTube](https://youtu.be/LvySJGj-88U).
  
```{r}
#| echo: false

vembedr::embed_youtube(id="LvySJGj-88U",height=450) %>%
  vembedr::use_align("center")
```


* Supervised and unsupervised learning. [Watch video on YouTube](https://youtu.be/B9s8rpdNxU0).
  
```{r}
#| echo: false

vembedr::embed_youtube(id="B9s8rpdNxU0",height=450) %>%
  vembedr::use_align("center")
```

## Introduction to Machine (Statistical) Learning

[**Machine learning**](https://en.wikipedia.org/wiki/Machine_learning) or statistical learning generally refers to methods or tools that seek to derive insight or understanding from data by using *models*. Here by model we mean a mathematical or computational representation of some part of the real world. In machine learning, we *fit* a model or class of models to data. The goal of fitting models is usually one of the following:

1. **Prediction** - using what is known to make informed (hopefully accurate) claims about what we want to know. 

2. **Inference** - using a sample to make informed (hopefully accurate) claims about a larger population. 

For an example of prediction, suppose that we are advertising experts working with a customer that sales video games. Our customer cannot directly control their sales but they can directly control their marketing by deciding how much to invest in advertising. Say for example that our customer has three ways to advertise: via YouTube, via podcasts, or via Spotify. We can use our past knowledge about how much our customer has spent *i.e.*, their advertising budget and the corresponding sales to make predictions using a model about how sales will be in the future depending on how the company changes its advertising in each of the three media. 

For an example of inference, suppose we have data on how a sample of patients respond to a particular drug. We can use this to make claims about how a larger population of patients will respond to this same drug. 

There are two prominent broad classes of machine learning models:

1. **Supervised** - In supervised learning, data comes in pairs $(y_{i},{\bf x}_{i})$ where we view ${\bf x_{i}}$ (which may be a vector) as a predictor and $y_{i}$ as a response. Often, We the predictors are something we can influence directly like the advertising budget from our earlier example while the response is something we don't have direct control over like the sales from our example. Thus, there is an assumed functional relationship between predictors and the response of the form

$$
y = f({\bf x}) + \epsilon
$$
where we think of $f({\bf x})$ as the mean value for $y$ viewed as a **random variable** and $\epsilon$ as the variance of $y$.

We note that $y$ may be numerical in which case we have a **regression** problem or it may be categorical in which case we have a **classification** problem. 

2. **Unsupervised** - In unsupervised learning, there is no response variable. Some common unsupervised problems include clustering and density estimation. Both of these essentially seek to discover a pattern in the data. 

### Fitting Supervised Models

Fitting an unsupervised learning model typically amounts to estimating the function $f$ in the assumed relationship

$$
y = f({\bf x}) + \epsilon
$$
between the predictor and response variables. Let's consider an illustrative example. 

#### Regression

![Illustration of supervised learning through a regression problem.](https://www.dropbox.com/scl/fi/4zmi7ql5ooxcafkym0csb/2_2.jpg?rlkey=jj0j32tvr43xcn88i2via58jd&dl=1){#fig-sl-reg fig-alt="Figure with two panels. The left shows a scatter plot of data while the right shows the same scatter plot but with curve fitted to the data." width=8in height=4in}


#### Classification

![](https://www.dropbox.com/scl/fi/qch7u8vzepor8egwgres5/2_15.png?rlkey=uc3vbxxu1tvrb3a92qxo4ssgg&dl=1){width=6in height=6in}


### Complexity Vs. Interpretability

![](https://www.dropbox.com/scl/fi/507z03ox81b15dbxe1pqk/2_7.png?rlkey=vs3rp0x3h5o0qvik8zhjbngsv&dl=1){width=6in height=6in}



### Training Error Vs. Test Error

![](https://www.dropbox.com/scl/fi/1arxit27ttbfmi527iare/2_9.png?rlkey=ohyvt8c4ao38hq0ggaul5ykm8&dl=1){width=8in height=4in}


### The Bias-Variance Trade-Off


![](https://www.dropbox.com/scl/fi/nof2kpjta6p5mlg8nxycd/2_12.png?rlkey=3ubpphur6n0h1ics55k0fm38e&dl=1){width=8in height=4in}


### Unsupervised Learning


![](https://www.dropbox.com/scl/fi/1nlczor8v22ron9rd4keh/2_8.png?rlkey=mfd0jzwbdhejomz71qwvlx82c&dl=1){width=8in height=4in}


## Preparation for the next lesson

For the next lesson:

* Read section 3.1 from of *An Introduction to Statistical Learning* [@tibshirani2017introduction]. You may also want to read sections 2.1 and of *Statistical Learning with Math and R* [@suzuki2020statistical].

* Watch the corresponding video lecture on regression. [View on YouTube](https://youtu.be/ox0cKk7h4o0).

```{r}
#| echo: false

vembedr::embed_youtube(id="ox0cKk7h4o0",height=450) %>%
  vembedr::use_align("center")
```


## References

::: {#refs}
:::


:::{.callout-tip collapse="true"}
## Expand for Session Info
```{r}
#| echo: false


library(sessioninfo)
# save the session info as an object
pkg_sesh <- session_info(pkgs = "attached")

# get the quarto version
quarto_version <- system("quarto --version", intern = TRUE)

# inject the quarto info
pkg_sesh$platform$quarto <- paste(
  system("quarto --version", intern = TRUE), 
  "@", 
  quarto::quarto_path()
  )

# print it out
pkg_sesh
```

:::



[![](http://mirrors.creativecommons.org/presskit/buttons/88x31/png/by-nc-sa.png?raw=1){fig-align="left" width=15%}](https://creativecommons.org/licenses/by-nc-sa/4.0/legalcode)
